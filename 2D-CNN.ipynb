{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ad1721-c65c-44a3-8fd2-42ba619cf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import fcwt\n",
    "# Read EDF+ file\n",
    "def read_edf_file(file_path):\n",
    "    # Read the EDF+ file\n",
    "    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    \n",
    "    # Get annotations/markers\n",
    "    annotations = raw.annotations\n",
    "    print(annotations)\n",
    "    \n",
    "    # Convert annotations to DataFrame\n",
    "    markers_df = pd.DataFrame({\n",
    "        'Onset': annotations.onset,\n",
    "        'Duration': annotations.duration,\n",
    "        'Description': annotations.description\n",
    "    })\n",
    "    \n",
    "    # Get signal data\n",
    "    data = raw.get_data()    \n",
    "    return data, markers_df, raw.info['sfreq']\n",
    "\n",
    "# Write markers to file\n",
    "def write_markers(markers_df, output_file):\n",
    "    markers_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "def create_intervals(df):\n",
    "    intervals = {'ds': [], 'is': [], 'swd': []}\n",
    "    \n",
    "    # Initialize variables to track start times\n",
    "    current_starts = {'ds': None, 'is': None, 'swd': None}\n",
    "    \n",
    "    # Iterate through the dataframe rows\n",
    "    for index, row in df.iterrows():\n",
    "        event_type = row['Description'][:-1]  # Remove the last character (1 or 2)\n",
    "        event_number = int(row['Description'][-1])  # Get the last character as number\n",
    "        \n",
    "        if event_type in ['ds', 'is', 'swd']:\n",
    "            if event_number == 1:  # Start of interval\n",
    "                current_starts[event_type] = row['Onset']\n",
    "            elif event_number == 2:  # End of interval\n",
    "                if current_starts[event_type] is not None:\n",
    "                    intervals[event_type].append((current_starts[event_type], row['Onset']))\n",
    "                    current_starts[event_type] = None\n",
    "    \n",
    "    return intervals\n",
    "\n",
    "\n",
    "# Function to merge overlapping intervals\n",
    "def merge_intervals(intervals):\n",
    "    merged = []\n",
    "    for interval in intervals:\n",
    "        if not merged:\n",
    "            merged.append(interval)\n",
    "        else:\n",
    "            prev = merged[-1]\n",
    "            if interval[0] <= prev[1]:\n",
    "                merged[-1] = (prev[0], max(prev[1], interval[1]))\n",
    "            else:\n",
    "                merged.append(interval)\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Compute complement intervals for 'normal' class\n",
    "def compute_complement_intervals(intervals, total_duration):\n",
    "    complement = []\n",
    "    prev_end = 0\n",
    "    for start, end in intervals:\n",
    "        if start > prev_end:\n",
    "            complement.append((prev_end, start))\n",
    "        prev_end = end\n",
    "    if prev_end < total_duration:\n",
    "        complement.append((prev_end, total_duration))\n",
    "    return complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6664635-5d77-4d85-89fb-616fa6e1f01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ati4x1_15m_BL_6h_edited.edf',\n",
       " 'Ati4x1_15m_BL_6h_fully_marked.edf',\n",
       " 'Ati4x1_15m_Dex003(Pharm!)_6h_fully_marked.edf',\n",
       " 'Ati4x1_15m_H2O_6h_edited.edf',\n",
       " 'Ati4x1_15m_H2O_6h_fully_marked.edf',\n",
       " 'Ati4x3B_15m_H2O_6h_edited.edf',\n",
       " 'Ati4x3_12m_BL_6h_edited.edf',\n",
       " 'Ati4x3_12m_BL_6h_fully_marked.edf',\n",
       " 'Ati4x3_9m_Xyl01(Pharm!)_6h_fully_marked.edf',\n",
       " 'Ati4x6_14m_BL_6h_edited.edf',\n",
       " 'Ati4x6_14m_BL_6h_fully_marked.edf',\n",
       " 'Ati4x6_14m_H2O_6h_edited.edf',\n",
       " 'Ati4x7_14m_BL_6h_edited.edf',\n",
       " 'Ati4y2_11m_BL_6h_edited.edf',\n",
       " 'Ati4y3_12m_BL_6h_edited.edf',\n",
       " 'Ati4y4_12m_BL_6h_edited.edf',\n",
       " 'Ati4y4_13m_BL_6h_edited.edf',\n",
       " 'Ati5x1_10m_BL_6h_edited.edf',\n",
       " 'Ati5x1_11m_BL_6h_edited.edf',\n",
       " 'Ati5x2_12m_BL_6h_edited.edf',\n",
       " 'Ati5x3_14m_BL_6h_edited.edf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "only_files = [f for f in os.listdir('full_data/') if \".edf\" in f.lower()]\n",
    "only_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a3a014-4ad0-4fef-86a5-e1ed5c50cb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x1_15m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 12 segments: ds1 (3), ds2 (3), is1 (3), is2 (3)>\n",
      "{'ds': [(223.725, 261.9375), (1722.675, 1771.9875), (7459.225, 7516.7125)], 'is': [(1772.3, 1790.55), (7813.406493, 7828.546472), (9128.025, 9161.1125)], 'swd': []}\n",
      "No valid measurements found for class swd\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x1_15m_BL_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 138 segments: ds1 (57), ds2 (57), is1 (12), is2 (12)>\n",
      "{'ds': [(178.0, 262.0), (343.0, 496.0), (1475.0, 1501.0), (1511.0, 1772.0), (2003.0, 2246.0), (2255.0, 2288.0), (2317.0, 2356.0), (2437.0, 2519.0), (2581.0, 2636.0), (2674.0, 2718.0), (2773.0, 2798.0), (2834.0, 2874.0), (4021.0, 4075.0), (4098.0, 4196.0), (4209.0, 4380.0), (4531.0, 4728.0), (4849.0, 4896.0), (5617.0, 5746.0), (5779.0, 5909.0), (5929.0, 6089.0), (6582.0, 6714.0), (6749.0, 6869.0), (6885.0, 6970.0), (7015.0, 7087.0), (7232.0, 7403.0), (7410.0, 7570.0), (7602.0, 7692.0), (7754.0, 7811.0), (7931.0, 8210.0), (8271.0, 8444.0), (8648.0, 8825.0), (8843.0, 8890.0), (8907.0, 8936.0), (8961.0, 9072.0), (9106.0, 9131.0), (9307.0, 9369.0), (10911.0, 11248.0), (11268.0, 11393.0), (11409.0, 11650.0), (11706.0, 11762.0), (11901.0, 12022.0), (12075.0, 12199.0), (12581.0, 12980.0), (13026.0, 13479.0), (13645.0, 13760.0), (13780.0, 13953.0), (14042.0, 14090.0), (14183.0, 14345.0), (15724.0, 16497.0), (16544.0, 16672.0), (17354.0, 17804.0), (17849.0, 17940.0), (18059.0, 18131.0), (18288.0, 18602.0), (18631.0, 18688.0), (18913.0, 19317.0), (19509.0, 20039.0)], 'is': [(1774.0, 1791.0), (2522.0, 2532.0), (6089.0, 6099.0), (7812.0, 7829.0), (9085.0, 9095.0), (9135.0, 9162.0), (12023.0, 12032.0), (13960.0, 13969.0), (14480.0, 14488.0), (18603.0, 18611.0), (18690.0, 18698.0)], 'swd': []}\n",
      "No valid measurements found for class swd\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x1_15m_Dex003(Pharm!)_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 28 segments: ds1 (14), ds2 (14)>\n",
      "{'ds': [(12785.0, 13377.0), (13443.0, 14205.0), (14265.0, 14526.0), (16380.0, 16645.0), (16692.0, 17079.0), (17701.0, 17797.0), (17871.0, 18119.0), (18184.0, 18431.0), (18516.0, 19271.0), (19637.0, 19909.0), (19970.0, 20691.0), (20718.0, 20845.0), (20881.0, 21010.0), (21109.0, 21580.0)], 'is': [], 'swd': []}\n",
      "No valid measurements found for class is\n",
      "No valid measurements found for class swd\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x1_15m_H2O_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 14 segments: ds1 (4), ds2 (4), is1 (3), is2 (3)>\n",
      "{'ds': [(428.5, 460.45), (14231.375, 14290.025), (20006.275, 20095.275), (20149.5, 20225.375)], 'is': [(6745.3, 6763.575), (7186.85, 7199.65), (20225.475, 20247.475)], 'swd': []}\n",
      "No valid measurements found for class swd\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x1_15m_H2O_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 70 segments: ds1 (29), ds2 (29), is1 (6), is2 (6)>\n",
      "{'ds': [(216.0, 285.0), (314.0, 500.0), (549.0, 649.0), (2454.0, 2516.0), (2560.0, 2601.0), (2616.0, 2767.0), (2834.0, 2907.0), (3038.0, 3151.0), (5739.0, 5944.0), (6164.0, 6746.0), (6809.0, 6838.0), (6887.0, 6918.0), (6974.0, 7187.0), (7225.0, 7238.0), (9090.0, 9135.0), (9174.0, 9204.0), (9314.0, 9348.0), (9406.0, 9543.0), (11849.0, 11921.0), (13395.0, 13468.0), (13718.0, 13857.0), (14109.0, 14588.0), (14819.0, 14963.0), (16346.0, 16602.0), (19583.0, 20225.0), (20268.0, 20496.0), (20568.0, 20768.0), (20941.0, 21214.0), (21456.0, 21554.0)], 'is': [(506.0, 517.0), (2772.0, 2784.0), (6749.0, 6763.0), (7189.0, 7200.0), (20227.0, 20239.0), (20499.0, 20510.0)], 'swd': []}\n",
      "No valid measurements found for class swd\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x3B_15m_H2O_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 18 segments: ds1 (2), ds2 (2), swd1 (7), swd2 (7)>\n",
      "{'ds': [(12386.825511, 12433.343149), (19196.425, 19231.318098)], 'is': [], 'swd': [(126.075, 129.275), (1864.85, 1872.029), (2094.4, 2101.775), (2133.15, 2138.325), (2660.175, 2665.3), (2742.205, 2745.4), (2757.025, 2762.97)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x3_12m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 28 segments: ds1 (2), ds2 (2), is1 (3), is2 (3), swd1 (9), ...>\n",
      "{'ds': [(4224.325, 4374.1625), (5679.975, 5777.9875)], 'is': [(4142.8375, 4174.925), (9802.7, 9837.2875), (10130.8, 10143.975)], 'swd': [(927.125, 932.675), (1015.075, 1024.15), (1371.75, 1378.075), (1635.9, 1639.875), (2224.8, 2231.6), (2297.425, 2304.775), (2440.2, 2446.1), (2710.7, 2716.075), (2877.225, 2879.575)]}\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x3_12m_BL_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 182 segments: dds2 (1), ds1 (19), ds2 (18), is1 (11), is2 ...>\n",
      "{'ds': [(2508.0, 2614.0), (3787.0, 4131.0), (4224.0, 4374.0), (4454.0, 4836.0), (4990.0, 5026.0), (5183.0, 5413.0), (5569.0, 5778.0), (5885.0, 6273.0), (6323.0, 6450.0), (7255.0, 7540.0), (7725.0, 8136.0), (8402.0, 8525.0), (8647.0, 8747.0), (9172.0, 9271.0), (9891.0, 10131.0), (15202.0, 15721.0), (15850.0, 15905.0), (16144.0, 16266.0)], 'is': [(4137.0, 4174.0), (4838.0, 4852.0), (5027.0, 5047.0), (5420.0, 5437.0), (6279.0, 6312.0), (8140.0, 8153.0), (8530.0, 8551.0), (9813.0, 9838.0), (10664.0, 10683.0), (10822.0, 10834.0), (15732.0, 15742.0)], 'swd': [(927.0, 933.0), (1015.0, 1024.0), (1372.0, 1378.0), (1636.0, 1640.0), (2226.0, 2232.0), (2298.0, 2305.0), (2440.0, 2446.0), (2711.0, 2716.0), (2877.0, 2880.0), (3686.0, 3695.0), (3733.0, 3737.0), (3775.0, 3777.0), (4436.0, 4439.0), (7187.0, 7191.0), (7227.0, 7229.0), (7612.0, 7615.0), (7681.0, 7684.0), (12617.0, 12626.0), (12674.0, 12680.0), (12682.0, 12684.0), (12687.0, 12689.0), (12705.0, 12708.0), (12714.0, 12716.0), (12731.0, 12733.0), (12753.0, 12759.0), (12964.0, 12970.0), (12993.0, 12996.0), (13078.0, 13084.0), (13223.0, 13226.0), (13423.0, 13429.0), (14040.0, 14047.0), (14468.0, 14473.0), (14738.0, 14742.0), (14970.0, 14974.0), (15149.0, 15152.0), (16775.0, 16786.0), (16857.0, 16861.0), (16921.0, 16930.0), (16995.0, 16998.0), (17030.0, 17034.0), (17209.0, 17217.0), (17780.0, 17786.0), (17826.0, 17832.0), (17933.0, 17938.0), (18004.0, 18008.0), (18044.0, 18050.0), (18111.0, 18115.0), (18178.0, 18186.0), (18194.0, 18201.0), (18222.0, 18226.0), (18613.0, 18624.0), (19021.0, 19026.0), (19038.0, 19042.0), (19195.0, 19203.0), (19272.0, 19281.0), (19332.0, 19334.0), (20080.0, 20089.0), (20605.0, 20614.0), (20631.0, 20636.0), (20644.0, 20649.0), (20710.0, 20712.0)]}\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x3_9m_Xyl01(Pharm!)_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 424 segments: ds1 (10), ds2 (10), sdw1 (1), swd1 (202), ...>\n",
      "{'ds': [(311.48538, 2691.859649), (3952.0, 4643.397661), (4830.0, 9558.0), (10485.0, 11675.0), (12472.0, 12577.555555), (12796.982456, 12802.555555), (15967.807017, 16346.0), (16458.157895, 17415.0), (19170.760234, 19996.011696), (20821.0, 21162.988304)], 'is': [], 'swd': [(65.02924, 73.450292), (86.0, 96.51462), (101.964912, 105.438596), (110.0, 114.339181), (116.520468, 120.391813), (149.0, 154.964912), (158.602339, 164.076023), (174.0, 180.918129), (190.0, 193.45614), (240.280702, 248.0), (255.356725, 266.684211), (2772.660819, 2779.0), (2795.94152, 2801.415205), (2805.54386, 2808.491), (2870.0, 2878.251462), (2919.672515, 2926.0), (3421.0, 3428.555556), (3438.695906, 3440.508772), (3441.403509, 3443.204678), (9686.239766, 9691.80117), (10086.0, 10093.80117), (10124.918129, 10134.0), (10183.046784, 10187.0), (10195.0, 10200.0), (10204.0, 10214.25731), (10242.0, 10269.660819), (10296.0, 10300.0), (10330.625731, 10336.637427), (10474.918129, 10478.859649), (11804.380117, 11807.461988), (11811.74269, 11818.391813), (11904.883041, 11915.280702), (11993.0, 12002.812865), (12098.0, 12103.812865), (12240.619883, 12245.719298), (12402.0, 12407.035088), (12815.0, 12819.672515), (12824.68421, 12830.812865), (12870.081871, 12874.403509), (12881.093567, 12885.578947), (13005.0, 13013.450292), (13044.0, 13052.0), (13375.783626, 13378.0), (13424.0, 13427.0), (13495.0, 13503.0), (13505.251462, 13508.409357), (13517.02924, 13524.444444), (13656.292398, 13662.842105), (13671.836257, 13676.888889), (13712.0, 13718.532164), (13795.783626, 13797.0), (13801.315789, 13809.631579), (13899.45614, 13901.561403), (13926.0, 13935.725146), (13939.0, 13948.567251), (13952.0, 13954.883041), (13959.97076, 13966.847953), (13987.309941, 13990.0), (13993.058479, 13998.339181), (14004.871345, 14010.666667), (14012.0, 14016.976608), (14021.461988, 14027.005848), (14047.181286, 14051.134503), (14097.0, 14102.444444), (14106.672515, 14110.549708), (14114.777778, 14120.0), (14123.058479, 14127.368421), (14130.672515, 14137.760234), (14146.023392, 14151.654971), (14184.058479, 14196.081871), (14215.0, 14219.824561), (14232.760234, 14236.690058), (14252.0, 14260.976608), (14266.0, 14274.923977), (14287.152047, 14291.467836), (14310.0, 14319.795322), (14324.859649, 14330.631579), (14340.0, 14348.730994), (14361.0, 14370.964912), (14378.0, 14385.719298), (14389.0, 14391.0), (14741.883041, 14759.0), (14770.74269, 14775.438596), (15023.0, 15031.883041), (15034.0, 15040.0), (15050.0, 15057.0), (15063.426901, 15069.02924), (15076.0, 15082.350877), (15089.497076, 15101.350877), (15302.315789, 15305.54386), (15523.549708, 15528.345029), (15531.0, 15533.643275), (15548.865497, 15551.368421), (15574.0, 15576.847953), (15771.0, 15779.766082), (15787.0, 15796.824561), (15802.22807, 15806.748538), (15810.80117, 15814.918129), (16413.0, 16427.140351), (17527.742, 17531.005848), (17605.0, 17613.356725), (17621.0, 17625.68421), (17797.549708, 17800.929824), (17839.555555, 17845.0), (17857.631579, 17865.415205), (17866.807017, 17869.935672), (17895.0, 17899.339181), (17901.690058, 17910.678362), (17913.409357, 17919.654971), (17924.736842, 17929.461988), (17933.532164, 17937.0), (17946.444444, 17951.017544), (17974.280702, 17977.836257), (17984.666667, 17987.871345), (18010.409357, 18013.0), (18140.637427, 18146.859649), (18156.847953, 18165.730994), (18175.520468, 18181.894737), (18190.0, 18194.245614), (18203.0, 18208.690058), (18256.508772, 18258.68421), (18265.491228, 18269.947368), (18276.473684, 18281.959064), (18318.830409, 18321.929824), (18326.584795, 18330.807017), (18341.590643, 18345.204678), (18349.0, 18351.94152), (18353.818713, 18355.97076), (18359.0, 18362.140351), (18427.578947, 18432.25731), (18439.964912, 18445.0), (18453.643275, 18461.0), (18478.596, 18483.994152), (18496.953216, 18501.982456), (18526.0, 18531.0), (18535.0, 18539.900585), (18572.48538, 18578.350877), (18583.0, 18587.508772), (18594.0, 18598.877193), (18603.0, 18606.222222), (18612.0, 18615.678362), (18625.0, 18629.982456), (18634.847953, 18638.766082), (18701.690058, 18708.0), (18716.736842, 18719.953216), (18725.0, 18730.245614), (18739.0, 18744.596491), (18749.918129, 18752.900585), (18757.824561, 18761.321637), (18779.005848, 18781.54386), (18797.415205, 18799.0), (18801.216, 18803.614035), (18832.771, 18836.345029), (18890.71345, 18896.0), (18900.51462, 18904.421053), (18920.736842, 18922.584795), (19005.187134, 19010.0), (19024.421053, 19027.204678), (19033.0, 19039.116959), (19042.584795, 19047.801169), (19054.321637, 19058.146199), (19062.0, 19064.415205), (19077.239766, 19082.210526), (19093.315789, 19099.298246), (19149.304093, 19152.625731), (20070.0, 20075.0), (20086.0, 20092.204678), (20107.0, 20112.274854), (20115.48538, 20118.573099), (20139.315789, 20143.163743), (20144.304093, 20146.801169), (20165.0, 20169.0), (20174.0, 20178.497076), (20205.584795, 20212.140351), (20220.678362, 20225.064327), (20227.087719, 20229.309941), (20275.532164, 20280.263158), (20338.988304, 20343.0), (20349.812865, 20354.883041), (20360.0, 20366.0), (20370.38, 20373.456), (20378.48538, 20384.368421), (20402.94152, 20407.321637), (20410.795322, 20413.473684), (20431.216374, 20436.0), (20452.461988, 20457.520468), (20465.0, 20470.48538), (20486.0, 20493.567251), (20509.385965, 20512.929824), (20528.94152, 20535.0), (20725.0, 20733.777778), (20738.0, 20745.0), (20748.730994, 20752.0), (21377.467836, 21380.426), (21383.116959, 21390.847953), (21427.912281, 21430.964912), (21439.94152, 21446.988304), (21448.719298, 21454.309941), (21487.023392, 21491.707602), (21494.309941, 21497.976608)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x6_14m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 18 segments: ds1 (3), ds2 (3), swd1 (6), swd2 (6)>\n",
      "{'ds': [(2470.875, 2534.25), (3352.55, 3686.875), (5359.925, 5499.9)], 'is': [], 'swd': [(2209.3, 2214.775), (2299.075, 2302.46), (2310.575, 2315.207), (6297.384, 6307.837), (6959.6, 6970.9), (7142.125, 7146.85)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x6_14m_BL_6h_fully_marked.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 290 segments: ds1 (42), ds2 (40), is1 (10), is2 (10), swd1 ...>\n",
      "{'ds': [(2470.875, 2726.223329), (2762.04789, 2969.235), (3313.956542, 3695.220029), (4342.05257, 4491.295495), (4502.117925, 4760.669), (4787.225402, 4845.225), (5057.230075, 5334.949701), (5370.963785, 5499.9), (5899.105, 5985.974), (8133.596262, 8286.418252), (8368.988346, 8529.754701), (8552.544421, 8580.329467), (9154.440355, 9240.814), (9644.997692, 9748.021), (9872.016327, 9917.025), (10078.114458, 10222.023), (10229.799037, 10258.030346), (10303.974271, 10327.995), (10887.509019, 11124.635), (11140.018364, 11295.530047), (11371.018, 11406.044065), (12025.854813, 12120.20528), (14735.649205, 14822.56042), (14829.037, 15101.539392), (15247.539, 15452.022645), (15793.391804, 15829.564701), (15868.017972, 15989.022), (16042.840402, 16089.186), (16418.013299, 16681.04586), (17221.982776, 17276.305), (19435.585579, 19508.814), (19547.024, 19636.337), (19811.561589, 19907.432813), (19937.077, 20067.724), (20090.995, 20164.991), (20335.421, 20388.601), (20888.080009, 20981.028), (21030.29029, 21115.851), (21156.094028, 21206.332346), (21311.21, 21497.00057)], 'is': [(11305.020701, 11320.046402), (11441.002009, 11452.079112), (11495.037056, 11521.833785), (12138.99, 12154.681), (16101.069, 16119.77), (16683.139318, 16705.158), (19708.056991, 19716.687832), (20392.327, 20402.832346), (20652.409448, 20680.533), (21497.594028, 21508.551972)], 'swd': [(2209.486916, 2214.775), (2299.075, 2302.46), (2310.575, 2315.207), (4165.431, 4168.234), (4986.73014, 4989.533878), (6297.384, 6307.837), (6959.6, 6970.9), (7142.125, 7146.85), (7611.307944, 7619.784579), (7982.789, 7988.420093), (8029.144, 8044.536916), (8066.303, 8069.681), (8074.261, 8076.153738), (8089.765888, 8089.868691), (8812.035, 8822.339), (8846.796757, 8857.656), (8897.90657, 8901.65657), (8907.778, 8912.740682), (8951.149561, 8954.747692), (9024.950962, 9027.544), (9075.579467, 9077.542), (9596.427, 9598.740682), (10003.544364, 10009.058), (10488.410888, 10492.593), (11341.055, 11344.747), (11456.06, 11458.13986), (11741.95, 11744.649205), (11749.263691, 11751.21229), (11759.803411, 11761.485654), (11840.906215, 11844.142), (12540.030047, 12543.908), (12842.121028, 12859.018), (12874.686, 12890.709), (13285.973972, 13290.723972), (14210.026, 14220.078159), (14241.753393, 14244.720682), (14329.601, 14337.816477), (14451.026757, 14468.881897), (14471.830495, 14478.517411), (14512.59685, 14533.863), (14544.213, 14552.811804), (14562.480028, 14572.835), (14584.867, 14596.012738), (14621.811, 14625.152925), (14637.008065, 14642.961336), (14659.928626, 14663.288439), (14682.495215, 14685.900589), (14711.023252, 14718.282598), (14824.967177, 14827.700822), (15575.314701, 15580.090402), (15770.961897, 15773.207), (15843.85442, 15845.933), (16811.003804, 16818.601), (16824.812215, 16828.410346), (17156.057542, 17159.517), (18157.202402, 18163.16), (18471.071, 18476.083243), (18560.985112, 18571.788), (18789.679037, 18802.155673), (18815.496, 18834.048196), (18887.393991, 18904.636981), (18915.356607, 18930.244458), (18951.108944, 18965.379972), (18970.594925, 18977.445392), (18986.641654, 18992.529505), (18996.959411, 19007.833243), (19012.048196, 19017.471093), (19023.924, 19032.237449), (19103.910346, 19122.599598), (19125.534178, 19136.077402), (19149.643991, 19163.791187), (19170.957075, 19179.153336), (19187.622963, 19202.954738), (19206.696561, 19214.947729), (19283.622963, 19290.725), (19314.791187, 19318.884645), (19330.809878, 19344.674364), (19375.410346, 19379.207075), (19417.482776, 19420.132308), (19525.097, 19527.089701), (19724.304, 19728.37), (19914.421131, 19920.974), (20071.491, 20073.126), (20305.68515, 20309.049), (20323.58, 20326.231878), (20414.598701, 20418.935), (20441.673467, 20444.495897), (20499.734215, 20504.009), (20513.776271, 20518.220196), (20805.519262, 20808.743561), (20854.830009, 20857.341692), (21513.215, 21519.570663)]}\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x6_14m_H2O_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 22 segments: ds1 (3), ds2 (3), swd1 (8), swd2 (8)>\n",
      "{'ds': [(13502.4, 13607.725), (14519.775, 14591.625), (18703.6, 18788.4)], 'is': [], 'swd': [(126.25, 142.175), (173.6, 178.625), (228.825, 244.375), (254.675, 267.875), (275.0, 282.45), (283.2, 312.4), (321.6, 344.8), (349.925, 363.55)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4x7_14m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8639999  =      0.000 ... 21599.998 secs...\n",
      "<Annotations | 16 segments: ds1 (4), ds2 (4), swd1 (4), swd2 (4)>\n",
      "{'ds': [(5201.825, 5262.275), (5294.725, 5316.425), (9514.125, 9566.275), (13846.1, 13928.775)], 'is': [], 'swd': [(419.375, 423.375), (426.75, 430.35), (441.4, 443.475), (583.125, 586.925)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4y2_11m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 30 segments: ds1 (4), ds2 (4), swd1 (11), swd2 (11)>\n",
      "{'ds': [(11139.65, 11172.425), (12430.275, 12471.425), (12623.575, 12669.925), (17192.925, 17237.160174)], 'is': [], 'swd': [(1559.55, 1571.8), (1648.15, 1662.2), (1671.2, 1682.375), (1697.725, 1710.225), (1716.85, 1725.225), (1787.7, 1797.775), (1800.525, 1806.15), (1806.975, 1811.025), (1819.575, 1824.6), (1825.3, 1827.093), (1831.1, 1835.159)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4y3_12m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 19 segments: ds1 (4), ds2 (4), swd1 (5), swd2 (6)>\n",
      "{'ds': [(12245.05, 12258.2), (12501.625, 12535.755215), (15328.55, 15393.72592), (15496.075, 15676.558435)], 'is': [], 'swd': [(1289.5, 1295.175), (1707.875, 1758.275), (1782.275, 1802.8), (1814.625, 1835.575), (1873.925, 1883.3)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4y4_12m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 32 segments: ds1 (4), ds2 (4), swd1 (12), swd2 (12)>\n",
      "{'ds': [(3794.95, 3859.3), (3895.925, 3919.55), (4421.55, 4441.9), (18735.175, 18767.95)], 'is': [], 'swd': [(23.7, 35.8), (63.9, 71.825), (227.371, 245.775), (255.9, 273.65), (289.9, 317.025), (318.25, 327.05), (423.45, 433.725), (613.7, 620.675), (692.8, 699.6), (782.45, 795.675), (815.15, 821.6), (4505.3, 4510.525)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati4y4_13m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 32 segments: ds1 (7), ds2 (7), is1 (2), is2 (2), swd1 (7), ...>\n",
      "{'ds': [(448.725898, 467.075898), (1536.950898, 1552.500898), (2376.325898, 2392.975898), (3465.425898, 3482.950898), (3701.525898, 3730.450898), (20244.950898, 20268.875898), (21272.950898, 21368.200898)], 'is': [(5427.750898, 5438.275898), (12027.075898, 12042.300898)], 'swd': [(977.275, 981.5), (1058.35, 1063.9), (1404.475, 1408.208), (3273.825, 3279.15), (4684.95, 4694.95), (8680.85, 8688.075), (8738.95, 8758.45)]}\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati5x1_10m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 36 segments: ds1 (5), ds2 (5), swd1 (13), swd2 (13)>\n",
      "{'ds': [(7210.5375, 7258.1), (10622.05, 10653.075), (11347.7125, 11381.6625), (16919.6125, 16968.7375), (17209.375, 17277.1125)], 'is': [], 'swd': [(2149.1, 2152.9), (2188.237, 2190.65), (2222.112, 2225.4), (2233.062, 2236.8), (2242.262, 2245.912), (2248.662, 2250.637), (2255.337, 2259.037), (3715.1, 3720.375), (3830.875, 3835.725), (3895.75, 3899.575), (6264.875, 6268.15), (6269.675, 6273.025), (6279.275, 6282.25)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati5x1_11m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 28 segments: ds1 (5), ds2 (3), swd1 (10), swd2 (10)>\n",
      "{'ds': [(7400.0, 7484.025), (14838.925, 14862.8), (16046.25, 16066.9)], 'is': [], 'swd': [(12.075, 14.55), (16.95, 20.3), (214.6, 217.45), (218.825, 220.925), (5552.775, 5556.55), (5714.8, 5717.325), (5732.2, 5735.925), (5737.4, 5739.4), (5907.125, 5911.5), (5923.975, 5927.275)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati5x2_12m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 28 segments: ds1 (5), ds2 (5), swd1 (9), swd2 (9)>\n",
      "{'ds': [(4542.55, 4654.275), (4802.5, 4866.025), (6046.575, 6127.075), (9657.95, 9730.2), (12419.575, 12474.45)], 'is': [], 'swd': [(2875.575, 2879.6), (2959.05, 2963.2), (4738.825, 4745.775), (5580.725, 5592.775), (5598.675, 5609.0), (5613.6, 5619.425), (5620.25, 5623.4), (5628.321, 5632.564), (5638.1, 5644.175)]}\n",
      "No valid measurements found for class is\n",
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/full_data/Ati5x3_14m_BL_6h_edited.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8640399  =      0.000 ... 21600.998 secs...\n",
      "<Annotations | 22 segments: ds1 (5), ds2 (5), swd1 (6), swd2 (6)>\n",
      "{'ds': [(1829.95, 1861.025), (6688.3, 6739.3), (14673.575, 14757.425), (16749.6, 16787.55), (17451.35, 17500.0)], 'is': [], 'swd': [(2359.85, 2363.15), (2425.85, 2428.8), (2430.3, 2434.175), (2436.725, 2438.95), (2440.525, 2449.1), (2878.125, 2883.625)]}\n",
      "No valid measurements found for class is\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your numpy array of shape (3, 400 * seconds)\n",
    "# For the sake of example, let's define seconds and sampling rate\n",
    "seconds = 21600\n",
    "sampling_rate = 400  # Hz\n",
    "total_samples = seconds * sampling_rate\n",
    "channels = 3  # Number of channels in data\n",
    "window_duration = 2  # seconds\n",
    "window_size = int(window_duration * sampling_rate)  # Number of samples in a window\n",
    "full_measurements = []\n",
    "full_labels = []\n",
    "\n",
    "for file in only_files:\n",
    "    data, markers, fs = read_edf_file(os.path.join('full_data/',file))\n",
    "    intervals = create_intervals(markers)\n",
    "    print(intervals)\n",
    "\n",
    "    # Collect all intervals from 'ds', 'is', 'swd'\n",
    "    all_intervals = []\n",
    "    for class_name in ['ds', 'is', 'swd']:\n",
    "        all_intervals.extend(intervals[class_name])\n",
    "    \n",
    "    # Sort intervals by start time\n",
    "    all_intervals.sort(key=lambda x: x[0])\n",
    "    \n",
    "    \n",
    "    merged_intervals = merge_intervals(all_intervals)\n",
    "    \n",
    "    \n",
    "    total_time = seconds  # Total measurement duration\n",
    "    normal_intervals = compute_complement_intervals(merged_intervals, total_time)\n",
    "    intervals['normal'] = normal_intervals\n",
    "\n",
    "    measurements = {}\n",
    "    labels = []\n",
    "    labels_present = []\n",
    "    \n",
    "    for class_name in ['ds', 'is', 'swd', 'normal']:\n",
    "        indices_list = []\n",
    "        for start_time, end_time in intervals[class_name]:\n",
    "            min_idx = int(np.ceil(start_time * sampling_rate))\n",
    "            max_idx = int(np.floor(end_time * sampling_rate) - window_size + 1)\n",
    "            if max_idx >= min_idx:\n",
    "                indices = np.arange(min_idx, max_idx + 1)\n",
    "                indices_list.append(indices)\n",
    "        if indices_list:\n",
    "            all_indices = np.concatenate(indices_list)\n",
    "            # Sample 2000 indices\n",
    "            if len(all_indices) >= 1000:\n",
    "                sampled_indices = np.random.choice(all_indices, 1000, replace=False)\n",
    "            else:\n",
    "                sampled_indices = all_indices\n",
    "                print('OVERSAMPLED')\n",
    "                print(len(all_indices))\n",
    "                print('OVERSAMPLED')\n",
    "            # Extract measurements\n",
    "            class_measurements = np.array([\n",
    "                data[:, idx:idx + window_size] for idx in sampled_indices\n",
    "            ])\n",
    "            measurements[class_name] = class_measurements\n",
    "            labels.extend([class_name] * len(sampled_indices))\n",
    "            labels_present.append(class_name)\n",
    "        else:\n",
    "            print(f\"No valid measurements found for class {class_name}\")\n",
    "        # Combine datafrom all classes\n",
    "    all_measurements = np.concatenate([measurements[class_name] for class_name in labels_present], axis=0)\n",
    "    # Convert labels to numeric classes if needed\n",
    "    label_map = {'ds': 0, 'is': 1, 'swd': 2, 'normal': 3}\n",
    "    numeric_labels = np.array([label_map[label] for label in labels])\n",
    "\n",
    "    full_measurements.extend(all_measurements)\n",
    "    full_labels.extend(numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bb84e7-05d2-4600-b626-01eb7a3f12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EEG Samples: 100%|████████████| 66000/66000 [01:06<00:00, 993.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import fcwt  # Ensure this package is installed\n",
    "from scipy.signal import resample\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "# Parameters for CWT\n",
    "fs = 400  # Sampling frequency\n",
    "f0 = 1    # Lowest frequency\n",
    "f1 = 21   # Highest frequency\n",
    "fn = 80   # Number of frequencies (output will be 80 frequency bins)\n",
    "output_time_samples = 80  # Desired number of time samples after resampling\n",
    "\n",
    "# Assuming full_measurements and full_labels are already defined\n",
    "# full_measurements shape: (N_samples, 3, 800)\n",
    "# full_labels shape: (N_samples,)\n",
    "\n",
    "full_measurements = np.array(full_measurements)\n",
    "N_samples = full_measurements.shape[0]\n",
    "transformed_data = np.zeros((N_samples, 3, fn, output_time_samples), dtype=np.float32)\n",
    "\n",
    "# Use tqdm to monitor the speed\n",
    "for i in tqdm(range(N_samples), desc='Processing EEG Samples'):\n",
    "    for ch in range(3):\n",
    "        signal = full_measurements[i, ch, :]  # Shape: (800,)\n",
    "        # Compute the CWT\n",
    "        freqs, cwt_output = fcwt.cwt(signal, fs, f0, f1, fn)\n",
    "        # cwt_output shape: (fn, signal_length)\n",
    "        # Resample time axis to desired number of samples\n",
    "        cwt_resampled = resample(cwt_output, output_time_samples, axis=1)\n",
    "        # Compute magnitude and apply decibel transform\n",
    "        magnitude = np.abs(cwt_resampled)\n",
    "        decibel = 10 * np.log10(magnitude + 1e-6)  # Add small value to avoid log(0)\n",
    "        # Store the transformed data\n",
    "        transformed_data[i, ch] = decibel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fe7406-6ba0-413a-ad76-46a670928f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to [0, 1]\n",
    "global_min = transformed_data.min()\n",
    "global_max = transformed_data.max()\n",
    "transformed_data = (transformed_data - global_min) / (global_max - global_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3592d606-5330-4bee-9b75-2d79c7e6bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageNet normalization values\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Since our data has 3 channels, we can apply the normalization per channel\n",
    "# Note: The mean and std are broadcasted to match the data shape\n",
    "transformed_data_normalized = (transformed_data - imagenet_mean[:, None, None]) / imagenet_std[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83999202-4b9d-4aa7-b680-6fb7b326b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedEEGDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (numpy array): Transformed EEG data of shape (N_samples, 3, 64, 80)\n",
    "            labels (numpy array): Labels of shape (N_samples,)\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image and label\n",
    "        image = self.data[idx]  # Shape: (3, 64, 80)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            # torchvision transforms expect (C, H, W)\n",
    "            image = torch.tensor(image, dtype=torch.float32)\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefff390-1546-485d-a5c4-5015a172a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /home/kglin/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n",
      "100%|██████████████████████████████████████| 20.5M/20.5M [00:02<00:00, 7.19MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchvision.models._api import WeightsEnum\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "WeightsEnum.get_state_dict = get_state_dict\n",
    "\n",
    "efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "efficientnet_b0(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c953ed8-7c83-4607-b43f-cf394f58c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import fcwt\n",
    "from scipy.signal import resample\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import AUROC, Accuracy, F1Score\n",
    "import torchvision.models as models\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e383b5-2971-43d1-a199-36e4a6da01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 52800\n",
      "Validation samples: 13200\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ 4. Train/Validation Split ------------------------\n",
    "\n",
    "# Define transforms: Resize to 224x224 as EfficientNet expects larger images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    # No need to normalize again as data is already normalized\n",
    "    # If using PIL Images, ensure correct format\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TransformedEEGDataset(transformed_data_normalized, full_labels, transform=data_transforms)\n",
    "\n",
    "# Define train/validation split ratio\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "assert train_ratio + val_ratio == 1.0, \"Train and validation ratios must sum to 1.\"\n",
    "\n",
    "# Calculate lengths\n",
    "train_length = int(train_ratio * len(dataset))\n",
    "val_length = len(dataset) - train_length\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_length, val_length])\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# ------------------------ 5. Define the Lightning Module ------------------------\n",
    "\n",
    "class EfficientNetEEGClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=4, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()  # Saves hyperparameters to checkpoints\n",
    "        \n",
    "        # Load pre-trained EfficientNet (e.g., EfficientNet-B0)\n",
    "        self.model = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Modify the classifier head\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average='macro')\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=num_classes, average='macro')\n",
    "        \n",
    "        # Class weights (ensure they're on the correct device in training_step)\n",
    "        self.register_buffer('class_weights', torch.tensor([\n",
    "            4.0,    # class 0\n",
    "            4.0,    # class 1\n",
    "            4.0,    # class 2\n",
    "            1.0     # class 3 (normal)\n",
    "        ]))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_accuracy\"\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        # Move class_weights to the same device as logits\n",
    "        class_weights = self.class_weights.to(logits.device)\n",
    "        \n",
    "        # Weighted cross-entropy loss\n",
    "        loss = F.cross_entropy(logits, y, weight=class_weights)\n",
    "        \n",
    "        # Predictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        # Metrics\n",
    "        acc = self.train_accuracy(preds, y)\n",
    "        f1 = F1Score(task=\"multiclass\", num_classes=self.hparams.num_classes, average='macro').to(logits.device)(preds, y)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_accuracy', acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_f1', f1, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        class_weights = self.class_weights.to(logits.device)\n",
    "        \n",
    "        # Weighted cross-entropy loss\n",
    "        loss = F.cross_entropy(logits, y, weight=class_weights)\n",
    "        \n",
    "        # Predictions\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Metrics\n",
    "        acc = self.val_accuracy(preds, y)\n",
    "        f1 = self.val_f1(preds, y)\n",
    "        auroc = self.val_auroc(probs, y)\n",
    "        \n",
    "        # Logging\n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_accuracy', acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_f1', f1, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_auroc', auroc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd9475de-3b6f-4e07-b383-bd43e06893d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 1650\n",
      "Number of validation batches: 413\n"
     ]
    }
   ],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ab5dad5-800c-4ab4-bc50-2e82214cf3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | model          | EfficientNet       | 4.0 M \n",
      "1 | train_accuracy | MulticlassAccuracy | 0     \n",
      "2 | val_accuracy   | MulticlassAccuracy | 0     \n",
      "3 | val_f1         | MulticlassF1Score  | 0     \n",
      "4 | val_auroc      | MulticlassAUROC    | 0     \n",
      "------------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.051    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139c6d00ef054a8e8afa51a72da1fbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "Metric val_accuracy improved. New best score: 0.843\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.010 >= min_delta = 0.0. New best score: 0.853\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.020 >= min_delta = 0.0. New best score: 0.873\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.006 >= min_delta = 0.0. New best score: 0.879\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_accuracy improved by 0.008 >= min_delta = 0.0. New best score: 0.887\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/kglin/miniconda3/envs/chanpred/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_classes = 4  # Update as per your dataset\n",
    "learning_rate = 1e-3\n",
    "model = EfficientNetEEGClassifier(num_classes=num_classes, learning_rate=learning_rate)\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Initialize TensorBoard logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"efficientnet_eeg\")\n",
    "\n",
    "# Initialize Model Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    dirpath='checkpoints',\n",
    "    filename='efficientnet-eeg-{epoch:02d}-{val_accuracy:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "# Initialize Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73f16a45-f77c-404c-84ff-c509b1064361",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, cwt_output = fcwt.cwt(signal, 400, 1, 21, 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfa2aa74-575d-4403-aea0-376bcba0e59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /media/kglin/NewData/Hack-ECG/to-classify/TEST1_30min.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 719999  =      0.000 ...  1799.997 secs...\n",
      "<Annotations | 0 segments>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing EEG Samples:   0%|                           | 0/900 [00:00<?, ?it/s]\u001b[A\n",
      "Processing EEG Samples:  11%|█▊               | 97/900 [00:00<00:00, 969.86it/s]\u001b[A\n",
      "Processing EEG Samples:  22%|███▍            | 195/900 [00:00<00:00, 975.03it/s]\u001b[A\n",
      "Processing EEG Samples:  33%|█████▏          | 295/900 [00:00<00:00, 983.90it/s]\u001b[A\n",
      "Processing EEG Samples:  44%|███████         | 394/900 [00:00<00:00, 977.46it/s]\u001b[A\n",
      "Processing EEG Samples:  55%|████████▊       | 493/900 [00:00<00:00, 978.69it/s]\u001b[A\n",
      "Processing EEG Samples:  66%|██████████▌     | 592/900 [00:00<00:00, 979.85it/s]\u001b[A\n",
      "Processing EEG Samples:  77%|████████████▎   | 690/900 [00:00<00:00, 973.47it/s]\u001b[A\n",
      "Processing EEG Samples:  88%|██████████████  | 788/900 [00:00<00:00, 970.31it/s]\u001b[A\n",
      "Processing EEG Samples: 100%|████████████████| 900/900 [00:00<00:00, 976.85it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Parameters for CWT\n",
    "\n",
    "\n",
    "output_time_samples = 80  # Desired number of time samples after resampling\n",
    "inference_data, inference_markers, _ = read_edf_file('to-classify/TEST1_30min.edf')\n",
    "inference_data = inference_data[:,:]\n",
    "\n",
    "inference_batch = inference_data.reshape(3,-1,800).transpose(1,0,2)\n",
    "N_inference = inference_batch.shape[0]\n",
    "transformed_data_inference = np.zeros((N_inference, 3, fn, output_time_samples), dtype=np.float32)\n",
    "\n",
    "fs = 400  # Sampling frequency\n",
    "f0 = 1    # Lowest frequency\n",
    "f1 = 21   # Highest frequency\n",
    "fn = 80   # Number of frequencies (output will be 80 frequency bins)\n",
    "\n",
    "# Use tqdm to monitor the speed\n",
    "for i in tqdm(range(N_inference), desc='Processing EEG Samples'):\n",
    "    for ch in range(3):\n",
    "        signal = inference_batch[i, ch, :]  # Shape: (800,)\n",
    "        # Compute the CWT\n",
    "        freqs, cwt_output = fcwt.cwt(signal, fs, f0, f1, fn)\n",
    "        # cwt_output shape: (fn, signal_length)\n",
    "        # Resample time axis to desired number of samples\n",
    "        cwt_resampled = resample(cwt_output, output_time_samples, axis=1)\n",
    "        # Compute magnitude and apply decibel transform\n",
    "        magnitude = np.abs(cwt_resampled)\n",
    "        decibel = 10 * np.log10(magnitude + 1e-6)  # Add small value to avoid log(0)\n",
    "        # Store the transformed data\n",
    "        transformed_data_inference[i, ch] = decibel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1726ca5-191c-4859-ad5c-6030aae56e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to [0, 1]\n",
    "global_min = transformed_data_inference.min()\n",
    "global_max = transformed_data_inference.max()\n",
    "transformed_data = (transformed_data_inference - global_min) / (global_max - global_min)\n",
    "\n",
    "# Define ImageNet normalization values\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Since our data has 3 channels, we can apply the normalization per channel\n",
    "# Note: The mean and std are broadcasted to match the data shape\n",
    "transformed_data_normalized = (transformed_data - imagenet_mean[:, None, None]) / imagenet_std[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b17369c0-dbcb-4b7e-a1ed-b6f3451bb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Resize((128, 128))\n",
    "inference_dataset = TransformedEEGDataset(transformed_data_normalized,[0]*len(transformed_data_normalized), transform=transform)\n",
    "    \n",
    "    # Step 3: Create the DataLoader\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fdd3376-88d7-4fb1-9ef6-281aa4b443c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6036, -0.8666, -1.2040,  ..., -0.4990, -0.5172, -0.5297],\n",
       "          [-0.6024, -0.8627, -1.1965,  ..., -0.4834, -0.5047, -0.5194],\n",
       "          [-0.6008, -0.8578, -1.1872,  ..., -0.4613, -0.4871, -0.5050],\n",
       "          ...,\n",
       "          [-1.1972, -0.9230, -0.5794,  ..., -0.3280, -0.2770, -0.2338],\n",
       "          [-1.1290, -1.0069, -0.8549,  ..., -0.5878, -0.5483, -0.5146],\n",
       "          [-1.0659, -1.0759, -1.0902,  ..., -0.8213, -0.7924, -0.7677]],\n",
       " \n",
       "         [[-0.7574, -0.6260, -0.4487,  ..., -0.2607, -0.2827, -0.2995],\n",
       "          [-0.7445, -0.6050, -0.4172,  ..., -0.2369, -0.2601, -0.2777],\n",
       "          [-0.7271, -0.5761, -0.3735,  ..., -0.2032, -0.2280, -0.2469],\n",
       "          ...,\n",
       "          [-0.2952, -0.0158,  0.3349,  ...,  0.4277,  0.4871,  0.5369],\n",
       "          [-0.6441, -0.5043, -0.3323,  ...,  0.0169,  0.0698,  0.1143],\n",
       "          [-0.9406, -0.9253, -0.9124,  ..., -0.3535, -0.3075, -0.2687]],\n",
       " \n",
       "         [[-0.1168, -0.1498, -0.1922,  ..., -0.3599, -0.3412, -0.3272],\n",
       "          [-0.1050, -0.1351, -0.1734,  ..., -0.3340, -0.3180, -0.3059],\n",
       "          [-0.0897, -0.1153, -0.1474,  ..., -0.2978, -0.2857, -0.2764],\n",
       "          ...,\n",
       "          [-1.0606, -0.5837,  0.0218,  ..., -0.0693, -0.0089,  0.0433],\n",
       "          [-1.0310, -0.7058, -0.2940,  ..., -0.3484, -0.2981, -0.2540],\n",
       "          [-0.9992, -0.8098, -0.5716,  ..., -0.5934, -0.5521, -0.5152]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b9640ef-058c-4ffe-bd66-b18bf99ac57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "with torch.no_grad():\n",
    "    for i in range(transformed_data_normalized.shape[0]):\n",
    "        ys.append(model(inference_dataset[i][0].unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91a04f16-a117-4e16-a826-67291a5900db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 2, 2,\n",
       "       2, 2, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "       0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3,\n",
       "       0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 0, 0, 0, 3, 3, 3, 0, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 0, 3, 3,\n",
       "       0, 1, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 0,\n",
       "       0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 3, 0, 3, 3, 1, 0, 3, 2,\n",
       "       3, 3, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 2, 3,\n",
       "       0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 2, 2, 3, 3, 0, 3, 0, 0, 0, 0, 0,\n",
       "       3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 1, 0, 3, 1, 1, 3, 2,\n",
       "       0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 3, 0, 0, 3, 2, 2, 3, 0,\n",
       "       3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1,\n",
       "       3, 0, 0, 3, 0, 0, 3, 1, 3, 3, 3, 3, 3, 0, 3, 3, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 3, 1, 1, 0, 3, 0, 3, 3, 3,\n",
       "       1, 1, 3, 1, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 0, 3, 1, 3, 3, 3,\n",
       "       1, 3, 3, 3, 1, 3, 1, 3, 1, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 1, 1,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 1, 0, 3, 0, 0,\n",
       "       3, 0, 0, 3, 1, 3, 3, 2, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 3,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
       "       0, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 3, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       2, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3,\n",
       "       0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 3, 3,\n",
       "       3, 3, 3, 3, 0, 0, 3, 0, 3, 3, 3, 3, 1, 3, 3, 3, 0, 3, 3, 3, 3, 3,\n",
       "       3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_max = np.argmax(ys,axis = -1).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15259a0e-e4a6-4028-ba93-04a9341949a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21528611d0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACKwUlEQVR4nO29e5wW1ZXv/Xu6m+7m2ghIc1e8RFQUEW+NOdFMSIjjZGSSj5M4mcEY47yZwTM65NUzZCbJMTk5+J58jMnMOBonUWZijImJ4sR4CcEjBkUQBAVUvICAQHOVbq59e+r9o3mefqpq711r79pVtevp9c3H0E/VvlXVrr1Xrb3W2gXP8zwwDMMwDMNkRE3WDWAYhmEYpn/DwgjDMAzDMJnCwgjDMAzDMJnCwgjDMAzDMJnCwgjDMAzDMJnCwgjDMAzDMJnCwgjDMAzDMJnCwgjDMAzDMJlSl3UDKBSLRezcuRNDhw5FoVDIujkMwzAMwxDwPA+HDh3CuHHjUFMj13/kQhjZuXMnJk6cmHUzGIZhGIYxYPv27ZgwYYL0fC6EkaFDhwLovZhhw4Zl3BqGYRiGYSi0t7dj4sSJ5XlcRi6EkdLSzLBhw1gYYRiGYZicEWViwQasDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkCgsjDMMwDMNkipYwcu+99+L8888vR0JtaWnB008/rczz6KOPYsqUKWhsbMR5552Hp556KlaDGYZhGIapLrSEkQkTJuDOO+/EmjVrsHr1avzRH/0RrrnmGmzcuFGY/qWXXsJ1112HG2+8EWvXrsWcOXMwZ84cbNiwwUrjGYZhGIbJPwXP87w4BYwYMQLf+973cOONN4bOff7zn8eRI0fw5JNPlo9ddtlluOCCC3DfffeR62hvb0dTUxPa2tp4bxqGYRiGyQnU+dt4o7yenh48+uijOHLkCFpaWoRpVqxYgfnz5/uOzZ49G4sXL1aW3dHRgY6OjvLv9vZ202Yq+cnyLfjgw6MAgAIK+PBoJ4YPGhD6XVMo4E/OH4vBDXV4dPV2dBc9FFDAgSMd+MiYofjy5ZPROKAWnufhoZe3Ysu+o76yAODQ8W4Mqq9FbU0Bh453o1j0MKSxDrU14c2DRgyqx5DGOmw7cBRtR7vQVFEOAN+xpoEDMGJwPbbsOxJKW/n7WGcPamsK+MTZo3GkowevbvsQHz1jFD5xdjP2tB/HY2t34M8vmogRg+vx9PpdWPX+gXI5Z4wegta249h3uBMAMHX8MBw63o3PXjgeo4c2ltP9/o3dON7dgz85fxw+PNKJX6zejj+bPh7Nw/rSlNr1oxfeQ2vbcQyorcG544dhd/tx7D3Uge4er9zmhrpa/OVlkzDhpEEn7mEXHnzxfWzZdwQtp4/En180ES+9tw8fHDiGP794oq+Olzfvx/v7juALl0wqX/+//2Ezth04iqGNdRhQW4MzTh6CN3a1o6O7Bzd+9DRMOGkgfrpiKz4+5WScMTq8w2RndxH/ueJ9fOwjJ+MjzeodKAFgw442rNpyANfPPBW1NQVs3NmGlzcfwPUtp6CuVs9c6+3dh/DC23vxVy2nYNv+o1j29l4UCgVcMHE4Lpw0HA+t3IZzxg7FhZNOws9WbsOUMUNx0akjtOqo5Jert2PC8IGYecao0Llfr/kAXT1FHDzWhYEDavHa9oO4ZPIIbD1wFJedNhJXfORk43pNWPLGbjy9fhcuPOUkHO7oRtPAAXjl/QNoGtjbj9qOdmFMUyPmtpyKMU2NEaVFc7ijG/e/sBkHjnTgr//b6Zg0cpAy/bHOHvz05ffx0TNOxu/f3I1tB45ixOB6nDF6CDq7izh77FD89vVW1NUWcMboIXhr1yEUPQ/tx7pQKBQwtLEO7ce7MKxxANqPdQEA6moLmNtyKl7evB+XnTYSL767D3sP9Y5Hm1p785c4eLSrPBa1He3CWWOGoramgKaBA9B2rAueB7yxqx1TxgzFlz86GQNqa7Cp9RD+8M5eXHbaSLy8eT8AYMYpJ2H6pJNi378Sj6zahlNHDcZlp42Uptl+4CieWr8Lf3HpJAxt7L2GX6/5AKOHNeC/nZlMP9tz6Dgee3UHhjTU4eShDZh97pjIPAeOdOKXq7fjyrNOxlOv78Khjm4AvWNGT9HDwPpanDZqMPYd7kT78a5Q/rajvccqx++uniI6u4uor6tBZ3cRIwY3YPKoQXir9VA5zaQRg3DwaBd2HjyGIY115Wdd+cx7ih6OdvZgcH0tjlT8O7QxPP1/+fLJmDhC3Z+TQlsYWb9+PVpaWnD8+HEMGTIEjz/+OM455xxh2tbWVjQ3N/uONTc3o7W1VVnHwoULcccdd+g2TZvfvr4Tr247SEr7yvsHMHpoA37/5p7QudNPHoLZ547BO3sO4xtPiJesXOFnK7eV/35k1Xa88e3ZmPvAKrx1YvD5yfUX4+8eWYuunmiF2W9f34Xf/PePAgC6e4r4yn+uBgC0nDYS83/5Gpa9vRe/WvMBfj//Cl++//dXr2HJG7v7DqyW13G4owv/a8555fq+v+RtAMDja3fg3HHD8Bf/vhIAcPbYYThvQlM53xfufxkAcGbzEMw4ZQTu/v3buP+FzdJ6fr5qO/7uE2fin5e+g+8+9Sbev/PqUJofL9+M//PMJuC34vNB/uRflgMABjfU4vMXT8LV/9z7u6GuBn952SmR+Sv51N0vAAA6uov43rObfOcW3XAxvrG4d+nzpzdegn868TeljSI27GjD7b96XVjGO7sP4WuPvhbK89jaHQCAe59/z7heEzq7i7jpRL8rtUFG+/G+vhSH7/zmDfxi9XYAwOOv7sDGb39amf6u323Cj5dvAfBW7Lor+eXqD6yWB/S+Rx/7yMmY/YMXhOdtPds1Wz/EPzy2PrLMP/7nP+DQ8W68u+cwvnftNF//S6qffXnRK9iwo+8D+M1vfxoD62uVeW5++FW89N5+3Pm03WecNp+ZNi4zYUTbm+ass87CunXrsHLlSvzN3/wNrr/+erzxxhtWG7VgwQK0tbWV/9u+fbvV8kt8bsYEzPv46fjTaePKx0YOrsc1F4wLpT3c0Y3DJ6Td8ysmPQA42tldTlPJ0IY6zPv46ThV8eV0xUdOxryPn17+74zRQ0Jp6utqMO/jp+MvL5tUPjagtoApY8Jf57U1BXxp5qnl34UCcO44sWrsWFcPAJQl7Rff3Y/OnmJZELnxo5Ol7QaA9Tvayn/3VHyJHe7oxrK39wIA3t1zOJTvhRPnVJTu8dGOnvKxI509vjS7Dh4v/73j4DFhOdsP9B5/pULTI2Pttg+V51/f3qY8L+PNXYcCv801fa9tPxg6tnnvkfLfW/YdCZ3XZafkXgLArrbj0nNZ0F0sktPuO9Rppc4VJzQFQLhPinhlq7pfJcFnpo3D1eeN1c53JDCGJcX2A0dJ6Q4d721P6Z63tiff/yoFEaBX4I3ipff2+36fN74JF58q1iKdM3aYb8wPasfntpyCmafLtUUA8BeXTkJDXfT0fd74Jum5U0YO8rVj3sdPD2mx00RbM1JfX48zzjgDADBjxgy88sor+OEPf4gf/ehHobRjxozB7t27fcd2796NMWPUaq+GhgY0NDToNk2bL17a+3W6/J19+K/XdgIATh7agM9fPBFPrNvpT+wBpfn2wkkn4fUPwhNT0Ppm2MABuG32FGxqPYz394tfvk+d21xuBwBs3X80NIEPHFCL22ZPwbb9R/HQy72ajYa6Wkwd3+RT2QFAXU0Bf3Pl6Vj00vvl3xdMHI6NO/UnwP/+R2fgJ8u3aOezgeweV1IIr3AxCRPLwIxJjT+/aAI6u4v47fpdWvlcfb55e9dnnHIShg8agFfeDwuiF0wajttmTyn//vEftqCn2Hfn/58rTsdTr+8KCTiV3PTfTsPT63ehI0JQmnHKSb6PxkrOOHmIrx1ZEzvOSLFY9Nl3VNLS0oKlS5f6ji1ZskRqY+IyHvpe1OCL0SeEuPoqywkKUPHMmWnoDCyVzQnaWudtgKoGYtq7W6cA9zuB+y3sw7HHy/QjtDQjCxYswFVXXYVJkybh0KFDePjhh/H888/j2WefBQDMnTsX48ePx8KFCwEAt9xyC6644grcdddduPrqq/HII49g9erVuP/+++1fScIUPa88ENdIZsFilb3IWQ70FEEjDxNRtVFlXbxqKaBgJKwXHZVG8viu57HNWaIljOzZswdz587Frl270NTUhPPPPx/PPvssPvnJTwIAtm3bhpqaPmXLzJkz8fDDD+Of/umf8PWvfx1nnnkmFi9ejKlTp9q9iphUvrSFQkHYibyKZZqgA0zpePA9LpWrGhSCdRUEiUXlFCD+4ioU/MejBqXQ0FN5IMN3qXRflF/i/K4zjFXcFEWqSwsavJTgtRUEx0RliOaKUDrV3OPYPdUSRn7yk58ozz///POhY9deey2uvfZarUa5iAev/KLKNCOuqbDjkmVnde1FYU5QXV28aun9KNF/iaptDMsSF8awPGlneG8aBDUJ4k7Uqxnxwhkq0wTLLWk0VHULpGJV+yoPitpZQEg1Ytwhs+zGlLrz85pVDx5LI7mgUP6/6iBvlxLUUAfP+X6HtOPxyqeX5dZdZWGEiOdVGLAGHqJXkSZvBL+EXJts/Aas/nMUNSXDMHTyOIYx1QELIxrIbEbK5x2byOOS5WTPcoab8GSVE4hfzkFcHcPy+OHhQpMdaAIZFkYA3xOTqb88z1O49pYsWIPFFoTpJVVL05ZexLABq9jYtfJ4lDFUcOipnGx0OrLOJEVZNipdc2W5wYEyTy9atcDCiD4uTEpU+PnaQTXGRS3L9DodqDsN1VsqTwasLIwQKVbYjPQb195MvWkIaRx7mfoDVdbFqxbKhCbC1TEsj6+6C9ocF9pAhYURBDQJBfED9OCVvxpkDzj05V42YFVIyRoGrJX1FgpiyTioCaEaOgnblq1vLyFJfl60aoG9LfKB6Xvv7PPN2auuo5EQacejLrdAtFBWOk9E5k4XFkaI9Bqw9r6owYeYbwPWwO9smiFFbcCaalMYB3HVxiGv8N1ksoKFkQhKE56HSgNWmWakush2mSa5ylmIMafa+ni1QgmcJcTRB5zHV9aJccaFNhBhYQRBw9BC4HcvlRFYZZ0stHeKoPxQ3ToRWAPHZMau/jAjZmvHSRLX8KqcxrR+w3xMPrV/WZOn/saaJjvoLI8Ex2eqIBl3ywzHpgUWRqLo6ygV3jTBRGJnGieIGlyC503XjJOapCrbE6rC8GVyTThjzGHhSIxsW4soXL2feXxn2aZNDxZGIijFFKmMwFojDzRSVTjvTWP4ssseH0Ohyjo544OfbnWRJxmOhREIlj98v3t/9e7a25emkpJ2IbjjpSg+iLLy8E/f0fDykWBJB3pfESoDVp3J3rZ6t9JWp1yHJQPWPH5luYJrX86ONccZZMu4Ubi7a2++UN1/0bJM8ADFm4b2waY659ZdZWEkgpqKSbE04co3ykupUf2AJF8U1oyYw108HxQQ/sii4OoYlsfvBxeanKf7xsIIAvE7EDZoBQIGrJJyQhvlBcoQ1h15QByvRBZnJChVUyP1CduWUEcmSfSJGrDm6A11DFcnK5dxQRMn+4AKwo/XDlrPPKQdJ0RglY3/oaLZgLVqKC8XKMPB96VxDd3lE9NLSOzSVeHgDd8m117CaiPN98DFd84FCgHVCLnLO3o/8/gBweOMHiyMRFD6ouiNMxKxTJNWo/oBSb7H1K9EJgy7fuYT8jJNss1gUiZPQx0LIwg8sMAnRfkvL/pFDX1UFAL/CusOGjOJjVKD7QyuCfuOB5aZVF8VYQNWr1yXaT+28nElCslvy4DVLBvD5Aj/e0/VLDiqGMnVpAqUxmeJO0KE0wLF+FhVvqpsVTuyhoWRKCq9OiQRWBWRMFIntAtvSm3SqUXL20dRsvG75NhLmCcok1WaE1r2b1xOIBuw8h0NkvQYyne8FxZGIigJHkXPK7u9ybwxXN3xMm1sSNy2jFxF8DKNOa66frpMFr0t+HVNbQOPYfZwYphxohE0WBhB0PvE//x8Qc9KaYKaEc//b7Bcta934LfSm8Z/TOrHHgoxL68/JPVXeAzpxStJKM6IslizF41de5MlzfmMZSMxxq69STTGAll6JBn1MdXSfMS4JVuC96UhLOVENMM5o2AWRiLoM2DtC3omD8Aa3WtzJKhmSrJxRvghMP0LsmsvS3dVRZ6GOhZGEFBnBuN0+DQj6p3ywgaWBd+/QLQmRGyUKlCNSAxTC4F0ZjtUILThXtrY2ijKZj6GNRF5oTcOhXzcyRt5a78qVki0AWu02oM6ritTOXZTWRiJpNK1t/JIHyUhxYVxWteAVRUOPk69KnTegcr2yXZF1sext7DKSPXr2oWXLgdQlzlY2AyT9C3hW94LCyMRlJdkKiKwysPBU5ZpeCKkkORdYpsRczjOSD4Iu/jTcPX55nHYdKHJebpvLIwACMYV8ak3y669fS9pcDKTySAiA9bIZRqlAau/XfKNmKLLLBHSpPgMWOX5QuVYHsNE9122DGZaNqMPybU3+WZU1OXm5FmJE/2N7NqbbDPyiImmT/XMI41TKWkKtPFPx3kia1gYiaDPtRcVrr3ix0hxe3RiYMoBcV80FdVmwMreK0yQkO0bMZ+rrr15fGVdaLMLbaDCwgiCBqx+k5+yN43X500je7NlEUJFG+9Rf1dWR47AGijPRINAlbyzhOOM9JLqXjCp1cTEIbhBJtlmxNEn7JobahQq7YatCKykdigKcm18Z2GEiIeKUOmCc4AbX436Bqz+88aDUULX7jNgTaYKxjKp2q9ypyBBtZPK0/1MSwhnA9Z0YGEkgpoTd8ijGLBSCnRLGHWWJIX2mirr9elO/jx05oFCwMffta9gXfLY/Lzf87SpsmHZjODaqmxZpS8Cq7icsOtpQVi+Lw3JgFVQjmQZJWSAG6HglBuwmr9IkfMVoWhR/bbmwbypfKNwVbXOuAPZm4aFTSsoDVhDm6MGzlOiiBCWciLbEZ09VVgYiaDyYUo1I176cUZkY0Z2G+UlU4+qVNNxs9o+WFwL65GmcMRTp5xgMEcKrsoiouan1dakxxlHb3nqsDASQaXgUfKWkXYyQq+qtolQhJWN8pJcpqmyh5DqYMYjpzZuaOKoBqxMNeFG36PBwgjCcUWC8TxK9BS9UHqg7wUOuvb2edP4l03UbaG1U1lG5IE+pBFYBZ5AKqzHGRGUG/ziNq2yymSRVHfSpWg92IYle2TbWkTh7K7MggtIq6Ummj7VQkvkoyB50xTiL9M4Ng6yMBKBSDMi3ygvGtc6gKuwZoQOe68wQYIu/XSbkWTaE5dcvrEOjDPZt4AOCyMQxeUQn4sy7oyKxBr8GxBpOwRGqYXwGZkvusgA10RVVwj8axNKmUmqF/P0grqGo3OVFAfmAyc6HHnX3oTb0V9Q3m5KnBFC+ZQxkg1Yq4jKhymzGSkJIaka7tkyYA0u0xh+GiV35fJw8KZtdWKCskh/XqqIuvL+emtMl2lcvWGi9qfW700NWJMtvupgYSQCrWUakgFrlc2ECcHLNHR4mYaJgifG/gkbsOYM39ykeHalfRtkAkXwRS4I1leiFmWUG+UFXPVkoeN9BrgRhk4ho9DyNZb+Jap3PbkGIw6qCKwUc9bS9VXzJGr70uKW56pw1J/isQSXcenvcUINionQtTeluk3qCS6X+88VQmmpeXXSICKNax/GLIxEUPnAiiVvmkCa8kScpleDY3FG8oRrL2FcXPOmYfILP9/04TveCwsjEVQuyfRE7tpLKLC65kEhkVI9ZUdebYFBnL4cBbfiNHWfjryQlFu1CFd3daWQlco6i1qDhut0196EGhSTPH5A5GmJxAVYGEFwWSM4cfX9CC5hlI+XzwfDwYvL96WJsKyWtVOU16RMuQdQITKvrxxCmTqU6vUVFdzUz7CeqrMZyboBAdKNwOra1btBeJmGli9XyzQuR2AtyJfHKR9r0fGoaKKOctdeQv40YWEkAtFXdJyN8vIo4WdBsgasyZWdCa4aaTDOQHft5edbTeRpqGNhBBGGobJgHgKC47TM8NRfVLS2o5wm1M7opkUbsAZ+hwxY5XmpZZqQqMFalQmEPH0wQaIM5aU42pny9soWIL/nkU4MooOi8knL3RGFOAQLIxGInlfwK6MvzkgyiL5WXDNg1flg1hlY1LEEDOOMGOVylySVFcH7T6kqVeWJo5Ona5C9aRJuh03yvgloX/kMwMJIJOJlGnFaShCeapsIkyLJ5axqW6ZxIdge4xYhmxFiPlcD6OXRGNQFbY4DTSCjJYwsXLgQF198MYYOHYrRo0djzpw52LRpkzLPokWLeo1tKv5rbGyM1egkCYWDF/So4Ishe33FYdzVyzKqly6UlmzAKi8z/OXrd1+mDgKVE6KNAa10DSrDWPOtvfP0ikaTrGYk+Du6MlaM+HGiu+XcgFWEywascTaoo4eDp7RDZcDqQsfsQ0sYWbZsGebNm4eXX34ZS5YsQVdXFz71qU/hyJEjynzDhg3Drl27yv9t3bo1VqPTREczQon34NbjdxfKfTIdi6pNM5KmO2aO5qp+TsC1l5jLVdfePA6cLkz2TgjCROp0Ej/zzDO+34sWLcLo0aOxZs0afOxjH5PmKxQKGDNmjFkLUyBkwBqhGSEbsApiXES53aoMWAuBdGKtTdCVmLbVdKgckVonTRJ8i6pOM8LLNFIKhfy12QbGEVgdFTfz9sYWIFddREdgLUQ+L1X5qrJ95xy7qbFsRtra2gAAI0aMUKY7fPgwTjnlFEycOBHXXHMNNm7cqEzf0dGB9vZ2339ZIfZYCRqwngg5nlAbkjRglXnTaKMI2x4Hfzh4O3FGHHsH45PkMo1JHgciEVPP9xeo2kC+X2GSviV8y3sxFkaKxSJuvfVWXH755Zg6dao03VlnnYUHHngATzzxBB566CEUi0XMnDkTH3zwgTTPwoUL0dTUVP5v4sSJps1MhDgb5VXhVJgIpGUaw5GTg57loy7GnF7Xz8rf+e7zeXxlnWhyjm6csTAyb948bNiwAY888ogyXUtLC+bOnYsLLrgAV1xxBR577DGcfPLJ+NGPfiTNs2DBArS1tZX/2759u2kzSQTDJod+B55njUQaCX659610FELHpL8V7atU3anijAQHIVV3DBkoBtph0pWjZASa4ZV+uVRy9H6ScNUDgnEHegRW7ks20DFgFS3VRz4uqgGr4bks0LIZKXHzzTfjySefxAsvvIAJEyZo5R0wYACmT5+Od999V5qmoaEBDQ0NJk1LhAL8X4Syh5jUe5yLOCMZlGtaZ/UJI0mW7aGyx7vnTcOTpwhKSHERrt5N0bWk501jGM+oCmO7JImWZsTzPNx88814/PHH8dxzz2Hy5MnaFfb09GD9+vUYO3asdt6sCLvjms9mVTYPJgZlIOW9aXrhwcxtXFgiIU+M3JmqijwNdVqakXnz5uHhhx/GE088gaFDh6K1tRUA0NTUhIEDBwIA5s6di/Hjx2PhwoUAgG9/+9u47LLLcMYZZ+DgwYP43ve+h61bt+IrX/mK5UsxJ7SsEfhdUwB6JOmBvhe4GPCLKwjShzsHXdCJyKpIJy8zbBRaigcfmTWQz19qXMpxRioKtqX1qTZvGopLuSkmBs6ubpXTn7Qo4eVaGkn2pTgIl20djC5dogD5PTddpg6eJ4WD14hblTVawsi9994LALjyyit9xx988EF86UtfAgBs27YNNTV9CpcPP/wQN910E1pbW3HSSSdhxowZeOmll3DOOefEa3mKFAILNbE2ynPgKykPkO6SsWbELJ+rpDr596MJPc8E7Q7IHxWJtCY+rk2cFFxoswttoKIljFDWzp5//nnf77vvvht33323VqPSJrxRXuAcwcgUEEwKhULlP6G/Rb+F7ZPEKxEJNr1fRBWGrlHiT6QBq8G6c5QBq+EGT9YMWO0UwzC5gbxrr6vSSM5Qb1AX0IYLTkdqRgT5ZOnk59waCXlvGgLBRxbaKA+e71/b5MOANf1RzNyA1a2XMC5JekAYheB3NCJsf5pow9taUHO6eZOyNGA1Je/aqLRhYYQAVZtBeTmqaxpMjmQNWM3yuQrHGXEbF2RfahNcn+AZPVzoe1RYGEF44otaDpEKI6FyBX8RVHSy9kXFPymV51tmiggHLzNQLAiWmFT4I6VaoGzAWlluwNjWv41eRVu8UBr/IJujN5SA7QnEf1f1C083PD29rv40z/a+t/qqkSyEEdJu50ID1nQw2yhPvkAeGvNDv6Pdsns3nSW0I0cGrCyMEAgFPQsu03jBP5i4UN4T1oz0kqYHBHfx/GDiTcMGyvZwYrJ3oQ1EWBhBUBPi1y30uvbSNCPBHS/LEViVBqxBTQldkpW6joXS6ffIJPfJo7m26dYs+woJa3g4zoga1d1x1fVThguPOk9tcHbX3iqC5rYbkQa0cV3DjjZzWBghIFKjVVJWjOTQgDVcjtk1+FT7Fm+Dr/0Sz59QnkhvnlhNco5kI7Cmk8cUnY3yciZHxSLkFUjMl80yTXQa0cdJWqHrk9YW9aNuqYSFEQqhZRpxMtpLFb85/QHaMo3Za1xtmhEezpgoyK693Jeqijx5DrIwgvAXhCruSO8x8QOWGbAGDUpldZfqC7cvfFBpwBqMM6I0YA1GYPW3y6QzRw1oJMOrJA3W8vN+kuhPX/wMjV4DR7/BOwlH+1LeXllVhNTIOYBcPiFdjLNpw8IIgfDeNP7zpcmgX2+Ul9DFq4qVLtNElOnWKxifdJdFoitzdD6Dyy1LGqrdWBZ3yLROl71ptMpPtvjcwMIIgShvmhKUiT9HWrNMId0nY2+a6noI6brSplYVE4Ogiz9VAk/LDkOXPL6yLjQ5T/eNhREQlmUifotjWYhjdUQty+hYP1O/dlSpQhE2y3UVIvPKyrExnpWuzV+uKs6IPF2o7By9oBTSNGAlBWB11NU4q3k2i7DbQTW+y6s0pv0lredpUo1qeTzam6YQuTxOHvsVyVwbB1kYIRD8kpZqRkjBexzrAY5CuU3mcUaq6xmk6Y7p6IczE0HeXXur641ND9f2n1HBwggAf1yRgAGoINIdNRx8nwFrIXRMVpaNCKzBvCZzbyH0R/VQZbJIuss0OVvhrrZnTSUYxZNsM+KotJm3jzjZRqYATfMedbUqA9lgOum5yNzpwsIICaIBa0K1JxpnhFiuDtFl0F+DyvZTN22LNmB17TWMSZLLNEbh4NNDJ46Om9NsOri8aZtxnWkt0yQsoPXnflkJCyMEoqKmliD12SqbB5OCIvWbvsTVFg4+1cmfR85cELIZcdlohEAeX9mcKXMyh4URBF9a/3ezSGUm62PBrzRhOPhQWUGtS7h0UUhzkaGtrHzVxC4zCtUNB6/a0M6EUr2qL1t/28UaFJFxcbUNEra/3OJG03UpAqs/raMzbQq4HPTM9LGkFrbAII+eI0L4fPwYIqWy5KlcGwdZGCFA/cLoz3FGssD0yqptmSbdZREmD5j2cJfktUrh0bWJk0LOlVGpw8IIAZUBaiXsTWMP/dskMxYLa5VqqqzX255AlLfepdkqJ2TyyoeWaagGrAm1xwCX2mKCC0O9A00gU2XDshmhZZmAJqQm8FKHDVhPLAWEyg3H6gh1jgiVnfKchd4uNwotTeL66l2rcUaEbVPXEx2OPk+vaDRJ7qQb1rRR8qTp3ZNM2mqD2uOz2JVZGi/I9yt8BanFGTGoRx3fQ/00ek0FotIQl3KU3jRujYMsjBDw7/UihzfKSxuz0YgNWGPU1Z9n9BwRtBVz2ZtGRt6XaVzQS7gmcKhgYQTBuCLqZZkahdQakvDLBqxyf/8oTUllnnA7RWnDeXVe5PJGeQLjW1uYb5RnZ6jM0wtKwqUZhHESE0P0rHE1ABsFnTFGOI5HZKeO6xyBtcrwPTTRJOn5/7VNHgxYExvEFOVK70FEW1x7CeOS5DOmhuAPJEoNHQ8ZlybapAl+rNCXJt3xpqnsa6LWu7kY2EcetVFZwsIIAeoeD6QwI1U2EWaJeZyR6noIrrrSMu5AXZp06fm61Ja8kqeRjoURBB+YX/0VNCZSGQ6ZGTqFahe0T2AIK2mHcJlG0SXDG6F5vnJMvqfsGLD62yMq1/9bZgQXjjNSbcg1RGYXLY7eYpY/adiAVUzQEJ/6Jrt6j4TLtim91KYGrLI7TtkcNeppqcLNq+rSqSNtWBgh4NeMCKy6S/+ya2+qVHMMFR3S9IDgO54PRB9RFFwKDOdQU4xwY6x3oQ00WBiBOqhZAX61vkrilW6Up1jmCf3WMDiysY10VJ4kXihKiUnGGXFijLCI7TFbdXuycP2MgwvP2oVJie7am2gztPDbjGR/D20RV6PRW4YF114H+mUlLIwQqHxkInuDvo3ygsZ+dkh2o7xAm01DM1dktKmxULXH1IC12kjyPuQ9HLxva4B+1DGCk5XLxpSU/iv2rksH03rcNRl2ExZGKFANWDnOSKrwS1wizdk/vaoYe1A1Cy4JbHnTwrlInqYbFkYQjiui3JCuAOkTlr06qrVbmjGTJM4I2YBVjux9FxnNUrHjWivSQHGcERGpaiLSq4qJQdi1N7OmGFPZ1/LWflGk7r5zgd/iVNHlE9uRF1gYIRAVgTVpj41cxBnJoFyZcNLfDFtlV2vlLoQ8mKJLTff+969nbQp5194Mbqc0HLzgsH/ZLaEGEdphtfxki88NLIwQoAYPogzC1fZVzmSPz14n6YGTR85cUEBQNULL55QgX2kzksNx0wWlhANNIMPCCATLMoGQq+FlG/8jjorAqvbWKUjTRkFNqiozpEnx/HnoLoHyMk0o1es3jJXXSTkeLLta8Md48YR/m5etb5TtkgGraVqbZNLdAuMU2ZgyC82IVMsr0AhHnE8Ck3p6V/NNFmBOpCF401AGMg4HX2XURCzTlCDFGbHQHqYXp77iMiRNd0w2KswnVNsBl56vryk8cBrhmsChgoWRAEGDz+DDrFEYJskNWOUFUmKHCI9pGbAqlpYke4/of1PJywxC8rMXlqvdFHLZeSZNDwiH5ipGQXB8cFkzIqNSMMrbO1tQODrYi8BKaIcilWtLXyyMEIjairsvAmsy9ScbZ8QWyVy82oA1zZbkDxv3wSjOiIV6k6irP2vSnI4zonHcs70eTIANWNOBhRECBcWvSiidyi1Z1K0vIV3y3HabpDk+uxSHgpGj+DBX49DjzXtXc2Ksd6IRNFgYgciAteK36LykHNlAHRVuXpa2L41smUa0pBPOq/4qCizTlA1YS7FNVHnD+cIlmlGq31+uyphSbLgpcrvO0zoqBdlmgsbRdCV/i34L8zu6bJT3yS0O5GWaDKQRHRd9Vd9MCqON8pTnoj9vo2x8VHFMyO1wbBxkYYRA5Nrrid6aR82IS3tR6MJf6b246r3CZEfvZFXw/abg1PNNf0XGKi4EHHOhDVRYGEHYJiQYMTW0UZ7kAQcnx1Iq5aBAMGZKkijr+aj2JCUQ6N8HmRtdWMOTpxeUgu1HoPQYy9m04MKjzqINwWUaumbEHTzpD/dRRUiNq9GwlcaBV8MHCyMEKh+acKO80r+e+HhcEjVgjdnmkmbFH+tCnUdncFaVq2P4Vs0UfctSqPjbQpyRwE2naNLSDU9P799OffU7ShauvdL3WGjBGnE+AZIWwLlb9sLCCAVynBFCUfFbY5W4g0+mSyX8FgNI2XuF73kukLn+R+HS8/UL2Q41jEh/1cqZwsIIgurMQMTVUNwRufpN9sKo4paEShMapcaMM6IKYR/UNpw4QI3AKjM9i0uSW4bn6P2kkeo4nb9JgQG507v0dF1qiy5xI2lTIqdSlpuVcUYcGwhZGCEQOSF7/n9tk+YyjS5JX7uqYJ0NtqoZ2/dB6U3j2L3V8qbJ9fSmR1SwQylZLNPIxjLBnks+z7G0wsEbVkO9//2nV6phYYSASrNRCc2bxi1xNO4LneUA79rEmBV+u4iE17f5nmvjwhufx4mR+1p8XNN+qGBhBIEHVggLHyFvG8kDlr48CrN2WmhgyTKNMHR8OK+qPwYNEks/y6rAiEFM+MViYRApb5QnqKv8W/bL96cXzpujF5SC7TFbZfRJET5ddTXuT5NbMBy5Sbwg8fkEbqKGUXReDJILkN/z4PKK9jKNIp8sLaUdWaMljCxcuBAXX3wxhg4ditGjR2POnDnYtGlTZL5HH30UU6ZMQWNjI8477zw89dRTxg3OgpqADUmQvgkv+u1w6/G7tTGWLjluulXSfIZ8z/OD0d40DulGVAEP84ATY70TjaChJYwsW7YM8+bNw8svv4wlS5agq6sLn/rUp3DkyBFpnpdeegnXXXcdbrzxRqxduxZz5szBnDlzsGHDhtiNt0Voq+3AF0Xl+RqJRgKQC/jBuCX+c4HfOoZPxLTKpaWQAeuJPIL4HCJEE2HUsEGT6EWp9AckYZyRPL2hBNIUEPIcJI+JpljMugV95PlDSTVwmo9/paJpY3NkOYR2pEmdTuJnnnnG93vRokUYPXo01qxZg4997GPCPD/84Q/x6U9/GrfddhsA4Dvf+Q6WLFmCf/3Xf8V9991n2OyUiQiY1adCTOblSdaA1VP+jiJx411FudIw6Dn8ioqDVpwGzRLDIfgJyzQp3n+duvpTr6Du6hok6h55nn07BKkBdqDeyn+D55PE+D3KoQdTlsSyGWlrawMAjBgxQppmxYoVmDVrlu/Y7NmzsWLFCmmejo4OtLe3+/7LkqhIhj9dsRV3/GYj3t59mFCWW/Lo/3nGv8x29+/f1sq/91BH6NhvX9/l+z3/F+vwX6/t1G9cBYeOd+Hnq7b7jgUHiSMd3bj/hfewdf/RWHWV6OjuwY//sBkbd7bhx3/YjLf3HAqlef2Dg1j04ha8tv0gHnxxC4oE1cHPVm7Dhh1tVtoIwHcjkhIKtx84ih8tew+Hjncbl9Hadhz3LXsPm1oP4b5l7+HDI53StHsO9abdd7gDz2zYhWc2tBrXq+L5TXuweO0OtB3rwn3L3sOOg8d85w8d78KPlr2H7Qei+9SK9/Zj4dNvYuv+Izja2Y0f/v4dfP3x9db6YxyoAsSbu9rR1WNPPbJ572Hc/8J7ONbZg5+v2oZVWw6E0mzd39u33tzVjjuffgu/fGU7frTsPRzpMO9rJpT6nIp9hztw37L3hOOeizhmFqJESzNSSbFYxK233orLL78cU6dOlaZrbW1Fc3Oz71hzczNaW+WDy8KFC3HHHXeYNk2bYKhw/7JNAUMbB5R/D22sC0kkhzq68eCL7xPLD54LGjNpxBkR1SXIq+qPq973Dw4vvrvf186ovvzzV7ZhwVVn+44teul93+/H1u7AY2t34JJTR2BMUyPNcCqQ5I7fvBGZ5f975i3854qt0UUXgGGNdWiPmFjvX7YZdy1RC2d/+q8v+n43DRyAz144IbINf/Ivy/H+nVdHpqOQxpfVn/zLcrQd64pVxl/8+8vYvO8I7nz6LQDAS+/tx39++RJh2q/8x2q8/kEb/mvdTryxq/dj5I1vz8ageuMhS8iXHnwFAHD+hCa8/kEbHnxxC1Z+ve/j6VtPbMRja3fgvmXvYe03P6Us67p/fxkA8O7uw5g4YlDoPUiTYHwhnY+gFe/tt9aOP7prGQDgqfWtWLf9IACE+v019/S+QwtP9IsSl0zu+8hNo49/6YFXyn1Nxld/ugart36Ip9fvwhM3f1Sartd+WHzPKU4LqsfVZ8BKiTNiejJ9jN/sefPmYcOGDVi+fLnN9gAAFixYgPnz55d/t7e3Y+LEidbrofKPV5+Nc8YNg+d5+PTUMcI0wxrr8Fctp2BwQ11I2xCXJJdpAOBvrzwdx7uKWLP1AF77QO+Lvatb4K0i4eCxToxpatQqv9R+0QAZjIexcnP4q0vGQ1+5FP+89B38/s090jSlwVOHTbvD2pOsMF0u8YI3FtASRGR9YfM+v23ZC2/vlZbx+ol+WDk5dHQVMaieVpe4YfJTpfp2t/u/eF98bx8A4MOj9Ot/f/8R7Go7rtGwZKCGJAhytFMupJsKBSbvkkiL4l+6sSuiyASRyvdo9dYPAYA0TpI9mGjJqh4jYeTmm2/Gk08+iRdeeAETJqi/AseMGYPdu3f7ju3evRtjxogndQBoaGhAQ0ODSdMSYfKowZj/yY+Uf4sG5hGD63Hb7Ck41tmjFEZcVJvdNvssFAoFfPs3b2gLI5naZ8QYjM6fMBx/94kzlcJIXugv9jIuvjuuEudeuWg36mKb8oBr7rsqtGxGPM/DzTffjMcffxzPPfccJk+eHJmnpaUFS5cu9R1bsmQJWlpa9FqaIEGbkGDckVB64TGa1XJQtRZetpEWQ2qHOJ1+hyyrAiPyiuKM2KBUq9qANdwOnbKrBakhr+EjEShGjPO7RDULakGC45jp5pShc5lJBeHwCaltlGdQj8qAOH58EHpB6nglbo2EWpqRefPm4eGHH8YTTzyBoUOHlu0+mpqaMHDgQADA3LlzMX78eCxcuBAAcMstt+CKK67AXXfdhauvvhqPPPIIVq9ejfvvv9/ypWRL3+Qdkc6t5w9Az1XMJeIORq69jDIy3YzQIfLyvBjGFfL0xmhpRu699160tbXhyiuvxNixY8v//eIXvyin2bZtG3bt6vOmmDlzJh5++GHcf//9mDZtGn71q19h8eLFSqPX1AnFFSEn9+WTpicYIynLjhuB1aBHZq3eS7L+vAldUfQbWaXKnluSBA3xdXCxP7nYJhWqDUppEVhVmvaCNF+4HLNzWaClGaF8oT3//POhY9deey2uvfZanapyR5KTZ9IGrCXiXEEmcUZyvsU4FRvLLab1mdSdpiaHw8FTsTM+ZX0Ls6g/6TqzvqeuwHvTWIL6qmetcVBh0rQslxDi1uzwo9Aii0BQWVAtzysN4tmMuNeL3GtRNG70VycaQYKFEfiXO3pfYvUDFJ2nGgqFllEIBqzSZRph2nBek+5ItYFJirIBqyIN5QtetFFe3mwPIqNiVv7tuyeGrr0xt2lPc+LgCKxiSLEsDLD17WHD7Tw9A1b9ipQGrIRnQ4kPQgrXpGEikDUsjFiCupeLG9KyGBOtTZYDfH+aXBgmLVxczmIj7uqHhREE1ZnR381xDFijTE4TWcYxsmA1z2oD2/WaqqxdIGog7i8DdT+5TCsUCoUYyzTu4WKbVIRCRATOReYnaDTiRmB1bRxkYcQSZffYBJRfLhuwmmyUpzUwKgr2G7DK0tDrchVjQ1TTfLENWA0rNkDPgLUKOkPG2LInSWITx6RgA9Z0YGHEEtVgwGoijbho7EbF5UdhSp6fRySWL63ahRNz11737ouDTSJQhQNMgrAwgmij0lB6keEo0VBIt67ePDIDVmKckegqpOVkZeyZZL15GyLyORAzLpE3o+28oxzXKXFGFM+rvIkpyYA1Ol6JK7AwYgmdDqJLess0BgasCYWD16m7929x/f1hIpf2hYzCwSeleBa+B1r5A7+rvG8kYSdlzZtGs5xS8my8aczy8UZ5erAwYgnqRF6NSwNZEVcAcu3LQIaW+yqPbMwJVBpZJnn4nuvBwghE4Xkj4oxIlk0UFfhyQ/pLM86IsG3hvPQN9Sr/prkqi75YdOqJSqOOwBpdjrB9OZMIo65TKqyYakZ8m5EZxBlJMRqvTvuCSVluE5OGQKtbRek5x9famWAQZ0S1zBLxG6DFraIt8SvOOTYMsjBiiULgX2k6xzpAnuHJpJf+og2xfZkuGmraxNRYvqqNoFPEaWcFB2FhBAIBwsiAlSYJhzUhelqZqHaI6ycuIQn+jsqZ1Hhu+zUWxXrhsYJhmEQgxp0yyN5nn0iJM0J0rHABFkYs0WfAmuM4I0ZND6tPbaJqPykcfJV//QKKGCsWnopRnJHYtUrKFTQmlgFrrNa4j+lIFHdplFaHXkGieEZpvdvGBqzU8s2KrzpYGLEEPc5Ios3oV8Q2YM3Js+DAXtVPXvoiwyQFCyMIDwRG0dNVyzS+JQKHDVgrN/Qjanr6vlgsT4KaBqwywURkwJrGwJ+mUOA3OIXwb73y4rYnXn5puXHrCiR2SW6rSaBTmhapfOdsRWDVTu/5/jUpwxSTegqQ3/+oOUB+0H/KNEZV30m3JGAWRizBBqxMUkRNAA7NqYwhSQwLlR8SbEyZPnkJHeAKLIyAKKlWnhcasNLKj9LC6HRf6gBjsoRUdh+LyGPydUnb4Mnuiyy+tnwMFi59wWeJ7fvgktdI0rKClgt0gu0wJW/vAFVTLk2jjMBqx8nBtdGPhRFL6Ph+65KWAWsckjNgVZyTLE+QC0iQVAdPu2FG/KpwIwPW9CKw6lylyxFYXRKM1ZtT2qpEM7nQgNVSW4h168IRWPVgYcQStt1ss8CkZVl+XcYdjPKiuY7jMcLkhJz0RYZJChZGgNBAEKUG043AqgjAGl4i0jFgFaYN5yVPur41ZkmBAYyWaShqygQH57wIIVT6jQBSxRfqUpd08Ta7tKRGQRknhJCWsrwS1w7ItXGQhRFL9C3T5DfOSBySCwGuUBkT6s9qELNZq6lnjnm+ir8NriTN5Q89t+fk2hEX1yYGGfZWaQz7puJXUiTtGedwt0wVFkYsQV+mcRezZZrsiL1MY6cZmUOynakCbF+aS/cqCddeYxy6LyVcelZUXHqkeYCFEeh7tOh701SmUy/LCJdk4sYZiTHt0nPaHS1K9SoNWAkxB0SGb2mMETa/pqJK8mmILMRhiGskmKpmRCutuzNa0n3SlsbWVr82j4GTvuBtFGekILcPpMw3yqdVIKSR1OUvxi1piYURS5js/+IaJuNVll8sefxaMqFaliLiUt2uvcmODHquve7clxLutYixDQsjEGgTIsYFbYOjAi0d5bxRYoNxrjQ4JjFI0iT6BOOMFMLH8kw1CyCV2J4kXbpvLnVFl+5LGRfbpEDmYAAQ4ywRNl6NH68kOn+asDBiiSS/bFLbKM9gSCyHac4g0IjfgFWcMKsxLBzTIkZLdDQjvjrjV2dSRJpf1lWjNXJsYpCRUZiRxMog1ZNwRS53yzRhYcQSZO/ZRFsRDyN5Ks8WrE4/DTq+yd/pGTce9pdp3MGlnujSfSnh4tJRFK5pHlyHhREIjEojhgaRFkS9TFMQ/h2VT9UePQNWfYhhRhIj2Tgj+Rol8jgQM3rkrU8yatQb1Cl/9h4jzCfxDVjdgoURSyT5YNNbptHHC/xrG7U3TXS6rBQFwXqTbIc/Lkjl3/Hjk5gsL6W7a6+GYWbombgj5NU4NDNQd8pOqg5V+kzCwRu+R9TPQHd6YbawMGIJ25vWMdH0m3DwEdeZxQDN2CVpzQhrXtKHb7keLIzAkjeNYWXhcPAacUZE8U4EecmCkoHHSenrUmcSpLSnHGdEGYFVohIQpEl7kg5+TcWp3jiWRkYGrEkh6gt698Y8byVJTDJJz1vWXHttaUY0C+rTwFbG0XE30IjO8ojufNI3NlO8cszOZQELI5aga0Yc6wE5hrUAvRT7SwRW2wasxoG37LYDcGticLEPubSkRsWhR5oLWBiB/kCgHYFVEWdEN/qrP63dpSG/oS2tjqSGCNuDs1DrY7eKxMjjQMzokpfeyMQltkYj8K+yHGWcEbf6HAsjlqgGA1YT+gzLousxCi1OPCe7TncMWJNriNyA1bRAcdkm7UkavTgjwYdisx3xCnNpXlC/c3ZumrYBqyCfy+HgAfoz5U+NXlgYsUQ1bJSXN+IbsObjaURdpm8dnUe2XJKPnsgwycHCCERGpBHpiUamonORyzRCo9S4BqzSpknrLtUZacAa+FeZVmuiLETmoUzCoi+qLOx2koxc6deMxBdMvJj6laS0caLriVOXzXbGFQLd2rVXYTRuzYBVM32Wrr1GBqwFyERMigGrSjzt26qD0o7oNK7Awogl6JqRHPUO1+knWoBI117pDyYv5GnSYGjwM9WDhRGIjEj1e5GxAWtQK6NTJzWdgaBEXu80cBmMGznQhFwbsEZoO/rL0ozLG+XFLcqlvuhid3KxTSoorrnK/CTXYHqIBNN2pAkLI5aoho3y4kAZ2M0MWFVxRsR/x67UAslFYBUu1AjPmkdgFf9tkt8mwnK1DFiNsxLKjmvA6s7MoF4aTaESRXob/VsX8wisFX8rHm/eBK2kYGHEEra1FFlg0rYsX6Rq8mBQErVM4xMeeGhjGNfIy1CTJSyMCDCZpFRfNqqFmLABawIRWA3ikZR92akWrDpQ1JQGxVqs3lnERpz9A9vXaVNwi71M41CndFGgda9FanrH58plb4UTgyh/RNmiclRpheccGwlZGLFEf40zknQ91E27qPcjLcLh4ON4fUScl0RgNfemodcdlT9pdOpyefdjl4QRFbYEFdNSZH09SZKux91emS4sjFjCxH3WNcyWaTQMWC2/dfGNBh1+GBXIgpqJjlXzwGb7i92uzUi8/C659ibdh1zaCTpJKp+oS7syuwoLI4gXkp2Sxx+/Q51PK86I6Lggr9E4V/Jlp6anGLBqDHMltaYqwmswvoZKg+SLM5JCZMTkDFjVdUUJLnHKo+dPSEsmrEsjv6VnIuo/cbUuLs1VSRuwep4drV1amK1EFwLjfkH4d+9vQX7lIKUzNqvilZAKSA0WRixhsjOua5hoCrL8YnFZ7W4Tv2uvSODyhGmZZEhmozyHBwYHyH2/5scbibYw8sILL+Azn/kMxo0bh0KhgMWLFyvTP//88ygUCqH/WltbTdtsnXAEVstxRlRScRytTIIdvM+A1V6ZpUGcFGck+JuyuRTxK4AaXdbF8SOmd2uusb/MZ9GANWZRLvW1xJdpTPLkrJMHNddUN19RelHZ5HJI8UrcQFsYOXLkCKZNm4Z77rlHK9+mTZuwa9eu8n+jR4/WrdppkrQ/SMuA1chmpLQMop81NiQD1qzijNgsK9KCVZzW9Np9mhijcPDpoWWzlGA7qglVv7EWDt7COk16BqzJVsT9spc63QxXXXUVrrrqKu2KRo8ejeHDh2vnywvVYMBqAk8G6dKfXXutX6lLN67KxgUV/caAteKZumSg7Cqp2YxccMEFGDt2LD75yU/ixRdfVKbt6OhAe3u7778kydKANXREJ84IoR29hlTmy070sPDaVZDqV3+lVX7BS9KU04bLTpJgu+PcHz3X3viuj65GYI1bl4vxM0q4NFVRN6eMVYdxvvTto8wMWAO/NZdLKOkp2njqvOQCiQsjY8eOxX333Ydf//rX+PWvf42JEyfiyiuvxKuvvirNs3DhQjQ1NZX/mzhxYtLNjE2SDza9ZZpkDVhdds10mSihq/+49louz2ZZVXTjk57kjWxGrLciXRyb951Ee5lGl7POOgtnnXVW+ffMmTPx3nvv4e6778ZPf/pTYZ4FCxZg/vz55d/t7e2JCiQ6Uqy8DKo3jTqdTtVkDx6NMsN57b1GpQHFxBiVIsioBlGhy3REM/IyAFbTRKjC9mXa3SgvpmuvQ5+piQf56if91b85p97zJWk9SAas7vSrKBIXRkRccsklWL58ufR8Q0MDGhoaUmxRfEyfOc2yWrxMI04bnVdej7wcGeVlkKQisKrOebIf4cPWv6o9T/mix9FQhevy1xuuK/7SjL88cd1mJSSLTk22WpWj8d0I5X2yZsCqm94L5UtNqDGoR72Le7wOZKv/uRb0MZM4I+vWrcPYsWOzqDoxqiHOSNLEGTxE9zc4wdt+ufLyqILB36oVV1x7hUbE1eTam7RmpIr7aCW+/WgybEde0NaMHD58GO+++27595YtW7Bu3TqMGDECkyZNwoIFC7Bjxw7853/+JwDgBz/4ASZPnoxzzz0Xx48fx49//GM899xz+N3vfmfvKmISnOisxxnxdUp19D2dqqlJTTx9Sm2OXMpIaFyxLbSJr42HCIZhkkDuFUGKs0SIW2UrXokraAsjq1evxsc//vHy75Jtx/XXX49FixZh165d2LZtW/l8Z2cnvva1r2HHjh0YNGgQzj//fPz+97/3lVENJPlcUzNg1WhTsEaaUGLXpY8S+jypbzDPU7/MSYWDj3LttaLGjhnRNSkBVfwe6FhQB/PGbJC8aG1cmhhUz9zGLfM8/XJE8YzSW6Uxq4m67N0/9ETRaAsjV155pXIAWLRoke/37bffjttvv127YXmjv8YZyZLYE4CVViSPVtCzRFvCJIVL6/f9xcA0aeIYsPZHeG8a2JmUlKHIFXWFloiEkUgkcUZEHiKCvCaePoXAvzJ0IrDqhIMv51F9pRG0ACLDNxvPO/J6g1/hsepSaypkBqzGNhGVfxsUkaQ2Kk5dYa2hGcKN8vrJDJ5VBNZSX7YRYVgXk2pCsasKinOGZdvyuHEFFkYswZqRaGJNyMIRwQv8sjs45WV6KfoampdW65OER5StdlTTMk2xmGwf6idym3RvGkYMCyOwMxCowv2q1HWxDFgtC0BC6T0ic1LjSrIGrMnUkRSZuDMyjEPkrd+rNOBxNRqF0B+qtKp5ya0BkIWRHOC2AeuJeihByUxU/qWlHZFrb0Blm6Zrb9T1Bu+7LZWy2K1UskxjWGXcpqZpwKojDdsM0R8u215ZWaO6FBvaxzibL/qXLNPB9NmqtwGpKN+s+KqDhRFLkLUPyTYjdbJcK48f2yEfT0PDfrWqJkUmG7gP2ccxJYSTsDACO+oqqgFr1L54olLkG+WJjF3DeclXJ1AlRhqwUstGn+BiGnXWFnkeF3S0ZNWG09cZVzB2aLZKfG8aIw2pyw8/TKEgjyhlOuZXli3LF06rOEfInyYsjFiiGjbKi0NiHhTKc9Eq2+SWDCLO2/Sm0diJ14YaO+7Ov2lOHDr92+XpzKWJgRrbJ6k6qPnS6mbG1Sg8aKyUX2WwMGIJcjRUp4YdPyYtixFzKjaxl2ncfRQ+PMnfwrQ8spFxaaM8l0j6SkzKz/vdzclQkyksjFiCHA4+pKILKPOEsUNixhkxeRN0PU4Io4XO4F+qt2+jO1F8DX/ZqhgcvjgjxItSamUiNRR66W3hvyeGrqu+v82NDW0Td0+YsLbKrKXiOCNGRSnLzAzFxdh4tp7nWYmBk5aIYvIeFRBw7VUYswqXaShL2Y5suGcLFkYsoXLtrcSx5+/DpHNm+cXSX7QA/t2JNdIyiVDt99jJy3OyUXRc1oi7AgsjtlBqRsR/C38n0mmpgpJ+BFYdSl9DJn72lK8AtdFX+O+oEl0cPorVPhMqsB7UzuoyTTxc+kpNftfedPJkSVBzrZoDZPmjzrEBKyMkScnXZQPWcrj1DExYszVgVRccUu3GagfdKNWOAav4b5P8SaNns5S3KS0b1Fsw2LmHVjZxdN2A1ZHy8wILI5agxxlxTR7tI/GvM+sWrDHzu/sopEROBlU8slkPB2+zrJiNc2lcSFwz4riHli0Kkr8ZMSyMWELV2Xyd0mBtQG7ASowzYvAm9IVMJxp7Wh4rStesdDP01S9O6JXPV5YdTWSEVV0D1hhTn6nHkrH7pORvev40XXs10jo8nzm1TKM6Z8u110K+tB6n6UZ5fscFuWiiH2fE/6+6HdHxSlyBhRFLVEME1vy59jo8u1hEz7W3eu+Jy/0ni0kyKRLvQiaaEfutYByDhRFLKNWsCuulONtJ02Ob6EONwKpD3z4zhPoDaUh73yiGLP+HSena1A1xcQCsYlkjEtuClt1lmngFu/SRkridmZNvll1Uka9jG7BqjM1Kjb1LnQ4sjFijxrEHa4KZa284jodNlCpjSn7P/y+53pjXE7JfjVGez6A0Kq3iF70+T/g3vQCjao3QaZ+tPuraIG6dFJ6f6fuYzQ7W1S88uQALI7aohjgjCbcuzhdR1K69gP32R5WWyZJITFuWPGN/mcZevtheTA5JOImv0hjJt/nr2A490lzAwoglTA1Yg5OsjlER2U7F4K2gGkklNfnZfo9FERDzMlhksW06wzAxiBnfg7K8Qoq9xHFG+h9VsVGeyTJNSX2qkVavfFWckeiy7YSdFpz3ojx9/EsdcYQIHdW0DW8aWXlJ5iGVK9RIxCoxVm5ZUabhw11B+c5Z6lO6b4RoW4i0NJOm1cjCwYfKNyu+6mBhxBLUJQKX4gnknfixHfKHdrA1Jhe4pKXjLmQJh55pHmBhxBKU8L2idOG4IIL8sjgjouOCvCZeN30hh6M8TkoGrBRvFzrljfKI52STtMjwTfasPI2v28itvgJGp3GEBGPNSAr1ReW3C11DKMwdSGz8xSvoP1Xl2qs8F//qPM8zN2D1tSUdTOoJjcO+OYAQZ4SwvEJb7iFOTA7AwoglknSzrRbiTcjROvq4A2Uwf/RSTfrTTmSVeZ8JFbgSgTVq92CjIFmGbUmCpPc/quIu6sOxud55WBixRI3Ct1e1dhj1WwXdgJWarqKdKKtGlCQ3bqnup0FpPgPWE376oS8UN0cPNmBlmHyhGlvi+l0WCrSxuTetSQ3ZwMJIDkjLgDVO5yQZsJqUeyKTKLSy30g0vjARnPRVpXlelDqbnlYHyvJRZb1GdcRUhiflhilZiDPOb3fXXk/4NxWXQnMrDbNtGLDGMGTPIs6IuQFrRRmKPsEfGL2wMGKJJN1sXSaLF6l0B+MORnl5Enp2Ecm1g2EYM1zVuroECyOWoGxsRMknSis3YBWlDec1Wc7R0AQCIE6CAi1HVFuoboayVKIvKpoBq7p9XkQaf9v0DfYo5VLqjVuHSwasUbYauvltanCqyWaE6k5vXD48bXsrL/BvqZw0MNJ0IajNhfDvUtpQfpIBK2EcVZ1zqdOBhRFrVEWcERMy+BLv86axW3ketAqRrr2s9HUC3fHApYmBe5AdyB9yibZCUa9jD5qFEUuQvWkcGnSCxNmbxnZaFSYqT6HGKYbxMGDBe4c4GmSzH4d7WN8oz6rNiL/cPD8nJ3ftzfH9ZGiwMGKJGsVM5ovfEbEsI44dIlmmES7phPPGWa+kT9DRo4XOgFK2Cynn9UIng5O0SoMkyK5sX1QckahYCUFDUh3tVhxsCC7xzFfFeWwIEsJytfL7U1uNMxI7AB8tWmcaKI0tLT1H832BCGuzljFadguMz6IYTqJzqmPBk6R+kp8wIyyM2MK2m20WmAgtWX6x2K7a1SUOHddeN6+gur5sq+laRLh4fa6+m4w9WBhJAZmELPytJQ9QJSBiMkGUQJtW4GU3XVJbghqkaD99qhGxLLps+HeymAyvSQekSgorho+WLz05A9Z4FqxZf68kvkrTD5ZpVBppkuEpQdNOU4xk3ZvosDBiiSRddl02YO1bRkm4ggr6PG0qk4kbIF4ykFXlRaZRlSurw6NkIJYVVY6VZZrY3jSi/ppMB3HV7dllDWgU6uVHS3U4UoYL9bABay8sjFiiGgxYk8ZW3++T9mOWGPNZxH2ZyQaskr+jU7uDLZdQmyTmgmyQx61hIekPGP3y3ezValT70TBhWBixBNlmJDjsUEL6xjZg1aesCozIXI7jYVAHpX5RuULNiEzbITJgJcQZiUJHc2IzAmsUVuKM+DREdiaO5CZ+esHWhOEE5hWXJq6kI7DGKSebCKz6FSmNVGMasJaX0ClzBxuw9j+qQTNiMghqeTPYds20Wpp+efE35iOm8+jCgatfkFa0Go5cHGWjPNdU4Dok3fb+YDPC6MPCiCVUG+WpCLv60suhC0DmcTlsCk+l8cREoq+chKWuuYrZihRnJFSemvjLNAZ54lWZGVb2NIlfhL88iwXG3ptGeyO15EjLzqyaKSAwvmgaKKcRgdU1WBixRJ4eugyTaxAtg9hEpAkob5RHqLQ0sFLaF1xaIScWnQ5Ynca5Pzrt8mtRDOsLGt9qF6Au0yZZGLC6rN20gfo+2bmJ+gJPaTk4ntDHuAsLI7YgjlBZrwerSLppcSYD0X0LFhfbjS1QYFRpcYdCM0O+/rtM44prL2WZRheXhoXEvUdM7JBc7dgK8uRW6wIsjFiCvGQS/K1vz1qRlygAaZQZzBP1QiU1RihjhpiURzD2dXXsqIZw8HlttylxhAuXBBPGEKXhKGV5JTpmEm25Oz+dqS7rBlQL1GduMianFWckjiRPq8eSS5/Qm0ZcdtRXrKwyyoZ0VK+D+OHg6Usv1rUHRnYtgmu10ZbY5fpTJ7Y3jUF+l+aMpL1pTAx8S8mz8aYxy6cKdukr36z42Lj2gcCaEUtQJ3KHxhw7aPToWHYTAgPWOIIXEP3VENNsJBNcbBNgx5PK/jKNxbJi2uq4pNJPKkBdf8OdJ5oPWBixhOneNFHLNr1pJHFGROUL8pq0jerLLvpiiYKSVhRLJNg2ygQgap80zkhCGoi4rp46ocbtGLDGMxIU1VtM0cBZntZOnZT3KZZ9VMbTmKrpth6jtvmqIJ5RWiJTpJZUZGSv8JIMj9Fh1N40GnFGVOcck5ZYGLGEoWdvv8L17y1t1XHMC+pPrr0uhhkx1QAIl/4Uvyi4NDEkrRnpL4qXPNlruAALI5YwXaYJbQin8VVkHPVVmk78t4osBhaTd5wUrdbRscP3NZjTgZzdMDVwtB9micu9R6y9DfxWnNOlLz/BEDZHfUlbGHnhhRfwmc98BuPGjUOhUMDixYsj8zz//PO48MIL0dDQgDPOOAOLFi0yaKrjVIMBa4yOSzJf9ehp+8rtTS1ScwbjYQiFLsGNigod31eeql1QXkgwLLsoKfXZ6IR4txIOPqYuXMtoWKvceIWE3w17VIPHUwnlMo0VDZf+uqUonlFati2RS7aS4+QPOp3GWMS1fqotjBw5cgTTpk3DPffcQ0q/ZcsWXH311fj4xz+OdevW4dZbb8VXvvIVPPvss9qNdRlT1968k8UXb9lmJGbdefpqKBE9MDo2wpzAzVYlh27fUtkUpI1rk1ReyeP4kiXarr1XXXUVrrrqKnL6++67D5MnT8Zdd90FADj77LOxfPly3H333Zg9e7Zu9c5CjvkRWpYJnhfkibtRHvmlqBgQy77stMx60VCj0yoNWBE+Z8eAtbK8aKM1T3FrgsawovKog77foDQqrX75oTIkf5vk72uLBW8aYbka+QOJbbhsVpQm+CufqA1YLTxHL44Ba/r3WSfqcQnVuB4ybhWUGXcTPFlduvnTJPE4IytWrMCsWbN8x2bPno1bb71VmqejowMdHR3l3+3t7Uk1zxqOPdfUSCscN2Uyj71xXXCyikwfqzqj1u491KE87+pXrZVmWb82eYF/eGcv9rT77/Wh41148MX3sXX/0XBJMZcPXBo/ikkbsCZaejI8s2EX9h3u9B17dmMrXt68H/V14gUGNmDVI3FhpLW1Fc3Nzb5jzc3NaG9vx7FjxzBw4MBQnoULF+KOO+5IumlWMXbtjROB1XJsE39bCqS8SY1bqhfZngGr3P3OJfI4eAdJeoITcd74Jqzf0WaU969+sip07Lev78L3l7xNyq97uUMa6zBicD0OHOnE1PFNWLP1Q70CKjh77LDQsfMmDAewVZlv+KABOHi0y7jeJMnyHTja2Y2vPfpa6Pjf/XwtOrqLwjzBseSkQfUV56LrVI9/4rF5/PCB2HHwWCBxdF2u4GQE1gULFmD+/Pnl3+3t7Zg4cWKGLYqmxtGJTIekr8CWyr/UUsqmWSLDN2ldOsshEWmCxrBio059A9ZKRg6ux/4j/q81G2rsuEs9wuuyZfhIOFbiwRsuxkX/6/fSJuhe2+GObkXbxH/LuO6SSRg5uB5HO3swtLEOn7twAtqPd2Hpm3tw9fljMev7ywAAZ44egh984QK8sbMd545rwq/WfAAAeODFLYIyJ6J5WCP+5Pxx5WNL/v5jWLP1Q3x2+nhMm9CE7y95G09vaA3lnXDSQPzptHH4t+ffIxtmm+J5BhtHit7jlCSUY109wuMyQaSSh79yKY509uCJdTtsNyvE1z71ERzp7MFdv9vkrFCpInFhZMyYMdi9e7fv2O7duzFs2DChVgQAGhoa0NDQkHTTrFIFsogRWX6xuByR0yayCfdLM0/FXYEv9apeptFg5ukjMWqIu2PIeeOb8BeXTgodnzq+CV09fZPc52ZMwLnjmnDuuCYAwDfHnQNALIx8pHkobrh8su/Ymc1DcWbz0PLfX7hkklAYue6SSTh+YtJ10QjavRbRmHnGKABIRRhpHFCLz144AQ+v3JZLYSTxOCMtLS1YunSp79iSJUvQ0tKSdNVOIjIw9f3WW6exms5n0V/w/2sDnbV0VTwWWZt0jbUio+HKmwfAvqupbsI8CcC29jSxib4RJe1c3HZSHitp40cBquCMIsPwJDDSkLoqZUsIL8freUspI6fK6iC0w2W0hZHDhw9j3bp1WLduHYBe191169Zh27ZtAHqXWObOnVtO/9WvfhWbN2/G7bffjrfeegv/9m//hl/+8pf4+7//eztX4AhkrxODstOKM2JC2co9KUNWlTcNoUzTexc3HLxOWVHIQqmL+pyOR5AMyvKXOr+6TJvILlH0OsZ/DhrCtKOTgNLOrLzNgjyJLZlAtz+I3oG0NDguCmc2ynFNvtMWRlavXo3p06dj+vTpAID58+dj+vTp+OY3vwkA2LVrV1kwAYDJkyfjt7/9LZYsWYJp06bhrrvuwo9//OOqcusFqiPOiMttq6QgkkYyIG71ZNdenZocG2BKOKkZ0SxPaSPkc+VO/iGIv4LNI3JWHk/+A8Ygj6sdm7GGts3IlVdeqXzZRNFVr7zySqxdu1a3qlxB/hKK1K0JYorE3SjPQMwoBP6NgjJY9EVgjU5bjjMiiE1Sup6gsaZKC0KKMxIwjoucfBSBRoKbzQlfGaowovP174QBq+CYYVuiypDeG0HPDccZ0WsVeZmGUJZyI7QEA6BR1P/K67T0JLUFwfJ77IWOJY1JNcol35jLK+UldEm8koLgmKocV+C9aSxRFd40BpeQpaovaxuCtJC1SzzhJtsWU4pJbdubIjoTcdxlvr46LUN4x118Ui62yVXyeq9YGLGE6TJNVNwRZVnkqK/U8sJ/24y9obVPjuXIgSYGrFEIr0drRYWWWPYFXwXyrxa2lz+SMmCNOxvQDFjF2tLossWJKiM1J24jYWY4lytU4zpFU00Z/+LGK3ENFkYskaNnbpW+ZRSNPDHTCk1GJIV66tPCtL1/a1ioRp324qm3Te19swoHL8qV1AQn1RoJl7ASaoNJxFXqB4J2yTbqlV+PPQNW3fThcSa1ZZq8CUJZN8AQFkaskdcu0IeJbYkOcV5qv2tvyerfX2Ds9ofKi0pPOkStTqseQOym6aoLpJU9TSy0w1eepEDZPVTd2yz2TDFBtZxctsVKWjNikifL5WCnn2j1wMKIJYzDwQfP69RpOZ0/T4GUVyfCaTkPpf6yASutHFk6VbtUwouO625Ufo9QngqZS6nQZkTxi4zPSFC/DHG0WbOmRNdlueNB3laZ2YtQexdDLqYtt9COUcuu3HgzjalXtz+U3gGLq2FkzPqu2LgUoC6vqEqmjc3UNK7AwoglyF4nJt4JhrEyZHmlJNxzs3bNjMqnrzoWla1h5EhNl9ASWJpY8cGwbrCsXtrTqd+/fBDd0KwMWCmveNLaNbMxMDuSNr62VboX+DcyvWNjBQsjlrBtTJoXTO0ZtOupdO2VueYqajAxYNXRfqiOyfMTDVglx/PUl+xMcNalEfFhqf1RvOdlE+GzjxNnBBJbrAQwCqSX6TINkwYsjFhCFWa5kqidYoVW8rI4I6IJVpCXLCgFyq/8V4YnUJ9GQZmY+mIehNOK1MlREVhJcUYkfwvTRl6Cf6nDliBGrzU7A1ZRnqQ+LuWCWtQSln6ZOhq1qHufVZwRSokuRmAV1Z+WfZRJNTrh4HWX3GSejsI4I4R4Ja7AwoglXHuwJiTtBmZ98LDt6qlZnHgXWZ38dtP1Jnb1Oy5+u9KKK2OyjKfr5ZHZMg1hckpcM2K8vJpN39bZBsAF8tXaPlgYsQTVk8OuAWtyS0N9edSZE+v4BAMureIoWiRHBcqcjYVC8nQN0q92jYtIui8JtaWkfJLjjvb9SrLqQybVqsZ10kefcvzTaUcOHuwJWBixBfGZu2zAGqfbkoz2Av+Syj3xr2jXXv9ygid+8TTsOoIqYNX9kIV4F3kXeRDfH3pfECeM3CiPWnywjJiFpBkOXlaw6NmFw8FL6pEcl3vTeAHXXnclL6Vrr8RlvhIrLtoejDpEMXSf0yFxg15L6bXLcaybsjBiCbKbbX4EVRoZdOg+e5KY5eTkYUh37RUcc22AKeFqu0RE2R85AcEgW5hNasDq/ruQ1d3P2zJNXmFhxBImRqK9+dS/e/PENGAltcxfXtmXnarx0UlESKwKwFT+gvMZiUZUSTJgpX91eZ7EcLFkMKuRNgq9UBrR90SrDBPPB6EtTTI2I7JyKRFY5a69kuOKPqZrM5JZBFYHDFg9w97gefr32QZmBqzy9XjKNhTKcPAR5bABaz/HseeaGnpLLuajB2WZI+6EFy4vfpvUBVCTaUy4jn7EFYvxy7CtmdBdplEasBLTRdWhU6cJlMkpaU2ADSE5TfK2x2POmluGhRFLUHftDUuzQddeep22l4Z8bSn4/pGS1HqqOgKhnfLyIkC6KmDo4NQSRwTSNXkdDVXCl6v7NR1ZXg5ehuwMWPUrFmmoZeeE+Uk2rjl4aBqwMGKJPLzMUcS6BsL7WjbujFENgPLbHDQSFdfphdLK0FEBB1XzyrIkaan3QZYuymbEVFCMqwqPGwzORrkUe5qoPhM6rli+8SidsbJ9WS3TELzUlP3aUjuM+6biV2LkR44GkJ+PrCAsjFgirx0gLlm8p2UDVsvlujrmJBFinpEjvYcaN9fVjxOSzYijvSgrzQgbsKYDCyO2MFkKQfSyjY06qQkLgr9tDqo6r3TY0Lcg/NufR+W2SDumagMFLcEh5hiXF28gwJbhIx3KvZHvzitOr5qU/DYjyU9eJv0ZAGoUI35BoHGMg+79jSIrocDEZkTlmBAzzIheOfkZIlgYsQVViLDmnUA0skt6YOxbetGZhPXaRNnSXccYUZ6W7kUSdQ1+rxYPcXQW0l17hQaslddghm9iNVmmER5Lph8mYUCtO4kmudeKdQNWgpeG0lDXkkBg3K8I77xtkq5Ht3jp8qJmea4pfFgYsYSRkahrJNw0W53fVjPjahbiBvdKwrXXVezYjNi9EbqGqupJOjq/TYwjsMrijFSesKYZkRw3rIDDwVc3LIxYwtqKiU6cEcKA1LtRHrVxleUXpHVXItqILjKtRv2lskW79vptBsXRC8pfCxWnpHFG/Lr2yMlHpbEiGbBSv44NjTSNXSj1bDEF+cO5khrQ4xiwyi5OW0jx/Llo/ZuQCEnEGVGcK71XiivQE7YlxyPeLVV5gVfUWULL8eRfJ46pIuVK8gnjjGguXWcJCyOWqKFu2+swJlqbLD8arMedcHR4S0LbkjZutkqMrjeNuIx45/vqtAtlAnJVEcAGrDTy1do+WBixBDnmR/A3IRqftCzLX1f+CKx6dVDQeaeVX3AGQlMSXwE6EUGF+cn1yD7/8yMAJ+XaG6s8mauuQf02XKp1MDVglb1ZBVS49hq3yo9cqDMt0LgpsTCLwCr/zQasYlgYsUSeHrpNTGKH6L7cweRCq3+lCp24jBRzeUJWVtSST2RZhvUar82HjG9tkNAyjaRcSjh4aZnSvkS/hkhPLQfjjJRQbpSXsD2JiqLnBYQ+O22h1Jsn8joVsTBijbx2gT6SvoI4r3TUDrVAfOPgcHl66QG9AZI8uenYRdCrTxU7rr2Wl+U0DSyVNkTEdFmj3rW399+kxU87Ac/SI2/h4PMKCyOWIH/pBBKG447QJ1T68ov5sgZ5ozydSZgwrPiM+wOFi7Y6lw58hi7Hcdf8g5vNxZmMTV17bfj2mhmwKou0ivy+mqtGdNzE1W1IDqHRI2FEkKXwv2+qEuxcrJk7tBd6r9Ihfj2JhIMnJMrTJzILI5bI00OXkXgQrZRcM9MqT7hRnlZ+YjqdMjXSpomTNiO6QofKy0Rz+cBpA1ZLdZm4SCvLM25JPGxs8pgmro4BUbAwYgnyRnnB37EMWM3q1MkT6dqrMUPovCTBen2uvdLy5TWYyFlR7Y27TENuh3SZJj8isI11d/sGrLLjkmUapQFrulOA8N0nGUYqDFgth2A1uY/K8rIyYDWY3tUGrBSNhh2tR56iNLMwYokcPXMpcSZsm26PsjpKlNvp+xpVD3ykOjWMP6MjtPr/jqNS1sprd5XGMFKmQGOU0EQiK1ZswEprhO4Xvcn1Om3AqjqXoQFrcLmzWiKw2iavUxELI5bI01eqjMQNWC291LYN7UroL9PEKyV20LMYHiNpY2N93/rz1nQ9VWpG4jcnc8oyfuICh6lqxLQl8WAD1nRgYcQSdAPWwG/DcuLUSctTsmBVp0vsq0FRrytxRtKiKsbClC8izuOm7IWUNWIDVkI+SaI8qPOzEgpMnrtqQ9QY4WC007j/VPtgYSRlklZ7Bw/rfJHGGY9oRnseOW2wbKFrb8D7RSWkUNS74fLUbRLNsEJPEk9yPKZ7h9C1V8MjSF6db6HGIL/gmFlTAuVKbi45f+A3MR3lOLXsqLJC6WjJyNBcexWGuhbaYNwvAy1LSzZJuh5tjWzEcWp5DsnWAFgYsUYOPiwSIYvw464s06SF7IswV8s0rjZMgIk3TeoII7ASjB6lmhH7yzS2yapdeQt6lldYGLEEdekgbGWtjjsiPVagqWoLJ/5HI+wLT82paR8a3ZLKuAeBnKJBU/6V64XOUzbKi/yyhXhwFBnMyuKM0G1GzL7+zXdHFf9tkj9uW/xl0I4BNEFNO+iZQhsZzBP1zLLbKC+6RLXXEL0u5f0y6FjBdy6tZTOTasLPtyA9JxzHlcvUpX+Dc0e4PGU5jn1AszBiiZp+eidtDE60vIIlkeAEEHPCC5cXlT66DN38OulEE4tTX+8VWFnvt35p+kKHZlHy5Bkt06gnp96TtjQB9l17s+nbedOM5Ku1ffTTKdQ+pt40Lhmw+tKV7FcjMifV8ZW1uibSJ0zOxkIhLhl/RqFrSxI3rQnGBqyax10iuzgj+ijjjFiLIUJJk4cn2wsLI5bI0TOXEusSCCNF2cBKc1QJJhcu00R9zVLap6EC9jz10ot/sznxVyL1PkhTiZYiYi6xBOszKUJnOUWvXNE9FKcVao0CiSmGzNTjuteX1TKN0kuNEoMkhsFwZRlG/UryHiVNngRpIB+CpQgWRiyR1w4QlyzeU8uBIsu4OubYmAAyx9V2CZBqRlJtRTLEtRnJkqyWIPMWDj6vsDBiCVPNSJxw8LZFoEqVXmnQslmD3hbsQT/9sHFtKE/KIqHwS10rfzzyJABbMWDVKCJOpFFdjYkoT9ITp0j9TrnmGunL0/f22Gq7baEuu2Ua/YplxqWAveWVPL3/FFgYsQata7gcZ8QMT1hvdA7NWqKWTUJRCEr5wnXSYqJETD6ScsTeNOq0Uch37U3Gnie+Nw29v2qVS6yLml97mUZRbtibJqItmRmwRq/TKL1pNOpSbdFgNg76G5CWcJJ0PbrFRwl51PJc04CxMGKJfm8zkiKF8qBp921ydW1Yz3DSzWvIU0htGwasSSPcJy9GRM7K4w5dpo/svGkyqbbfwcKIJci79kbEGREGM5LFGRGmDec1Cwfv/1eGSBNgI61vcJQZsCrSlI+XNDcV56VxRiJ++85Jvu7K9RHaRh32ZamEEVh99ZqNoj7jW4OpKa4GQ1qu8H6LEcYZIS6l6Lr2ivpC1NW6uFFen2E4fTlKhfwLXqzFpJTn69+piU0GyzQKb5pQWuKx4DnZ1EGOKuXY1ycLI5Zw7LkaEWfX3izoPwasyaSll2lBkLDQjrSQCyl5ugoxJAPWFNphQla3nzUj6VCXdQOqBVtSpo4RJj2uKlFrEyMCKwVb++SkJdFHrvuLricBwUF231z7slFhx2ZEo//E8BrRPQ6I7FGSncHEX9Pm6zS+vmSp6dJbYFh+noKeiTTU5b9JBqyUOnI0ABBgzYglqq1jUOnb/E7HkFDv5ZYZB1LK0UobiA0SlVpdb0ChHGMc1VONVy6xxK/PyNhQmD6ZiSQZTZDkuOwacvTlHMfLqPecnYs1NWC1sRGkdr05er55xkgYueeee3DqqaeisbERl156KVatWiVNu2jRIhQKBd9/jY2Nxg12lTx9pcpI+hrivNTiXXsDaWIKhLrr/jo2DML8GmlFUOwiXMGKZsT2spz0uJ4tSe+5gMBs2KakUe7aC8uG4ZZlt+yWaVx9mtWFtjDyi1/8AvPnz8e3vvUtvPrqq5g2bRpmz56NPXv2SPMMGzYMu3btKv+3devWWI2uZvTCwScnPfQZsNLcRymvazktyYC1r96gm61o197eqI7hgnXqDBrHmRjyiTbmk0WOJLv2ShatxXvTyH6YETQapOWRP4e4bSGXKzNS9n1Z6wkdsklJ2PMSnr9M44yoYvSQdsM21NL5jntmtye44aTLMkL8cPCENFXwAVyJtjDy/e9/HzfddBNuuOEGnHPOObjvvvswaNAgPPDAA9I8hUIBY8aMKf/X3Nwcq9EuUm0dIw/0GwNWnbSOXkOevi7lwkjydYTS2asSADXku+VKLcGaERr5am0fWsJIZ2cn1qxZg1mzZvUVUFODWbNmYcWKFdJ8hw8fximnnIKJEyfimmuuwcaNG5X1dHR0oL293fef61Bde6PQKSVJtz9qBNakPD3yINzFX6ahpZbdt/QMeeMPb1bG85QmBSNvGs0lvriYPnrZF3ehUOkyn6xdiGn5WckEZvXGjcCqW0P+0RJG9u3bh56enpBmo7m5Ga2trcI8Z511Fh544AE88cQTeOihh1AsFjFz5kx88MEH0noWLlyIpqam8n8TJ07UaWYm5GHyTBIb8Qf000cba+rENvGVF5Fex57EI9cvq8vMEsV80I9eylDnV7XKLrL2yV5HnXg4QWSaEZNn62KckRK2IrCa1iGj6Pl7dFqySd40I3mdihL3pmlpacHcuXNxwQUX4IorrsBjjz2Gk08+GT/60Y+keRYsWIC2trbyf9u3b0+6mbGpBm8ak2tI0otGRp+hnZXiyoQMWCMFEnM7EJ20mccZsVGGg7FK9IObqcTifE1YImxvQBn1gZAXOM5IOmjFGRk1ahRqa2uxe/du3/Hdu3djzJgxpDIGDBiA6dOn491335WmaWhoQENDg07TMsdanBGNgpLUxpTLjorAmlwTmBNkfY/zNnkA8Yy7ZUKHzqSUeJwRYTh4c6PHPHxKZdYPLWi+fBt92rrZVaaO19KM1NfXY8aMGVi6dGn5WLFYxNKlS9HS0kIqo6enB+vXr8fYsWP1Wuo41G5h5l9P/wIPHtYJvRynb1Nq0FsyqczniV17A2WLNTti7xZhPYG/VfdNFn9DtHDkeeKSyPdBthRBuCcmxB3zY12rqlwbZfj+ltiGEPIGj9twC9ep0xSKa68KPS2d6v4aLP+FvGmytSGyV76d9F7E+VB6xz4ytCOwzp8/H9dffz0uuugiXHLJJfjBD36AI0eO4IYbbgAAzJ07F+PHj8fChQsBAN/+9rdx2WWX4YwzzsDBgwfxve99D1u3bsVXvvIVu1eSNdUlpNJJqUOLd4L1H4s7aITKM7AbSWLZSvZFLhS9EhhhbAzGVsqwfG1R7tk69esu8cVH4NprlOvE8ULfSVs2EibLXcryMpo8eZkmHbSFkc9//vPYu3cvvvnNb6K1tRUXXHABnnnmmbJR67Zt21BT06dw+fDDD3HTTTehtbUVJ510EmbMmIGXXnoJ55xzjr2rcADTjfIo56Ub5REGpMKJ/+m2rRxnhJhXb4CJTlvZFsqXalSgKlGcEmV5EdcTNbmGDVjNRzSdidyKZsQT/22Sv0SxaNYWk7oAlQGrpzjbi2zykcYZMbhJ2RmwxtN+ZB6BlWC0bhuj56s8J/e0KR9TbYchyae7hYdrqzxGe9PcfPPNuPnmm4Xnnn/+ed/vu+++G3fffbdJNbnCsedqhJEBq05aW582lg3tSmgbsIq0NTHq002XVgRW28sjWZbhK0+qGREfVwlUouVRF1FPkr0k79prWl4295Q1I+nAe9NYwlY0VK04I4lKQIUU6lDVXg3inR2qYSxMeyKJ029lGhCXXDzFBqxm+YB8vG9ZCQVmmq+A9kOgdVbm5wisjCnV0C9MOreWjYTn/1c3n6pu3a/cyPJAMGAVnvD9o05Lbpf4uDAcfOAajOqLGasksXDwgkL0N10U/x1VjzI9svtq10X10VQ6p1ym0XmfZHfMM9W2BTacTMteLZ1q+j0sjFii2qRUKlm+qNbV9pbLs4WpzYi1+l1cY0kQEwPWcFpbrUkfV5uenQGrq3ekumBhxBK21JxZCjWikMU2XZa9wL/KtlRW7Em+6AJGouKN4zxy+3zlRXy9yV17w/V5kvrprr3iw8K+4rsGs0E0CQNWOx45tLqUZRDuj26kVZHmK+n5S2j0GGcMqgwHrzRg1UCqGKGHG1AVl5Zdjup+UOO2VD4bkteTpaWcPMHCiC2qq1+QSSs6KMVYNLZrb8Tv6ByW1NgBZF9mEbKINey45Vpoh2XNhCyJic2IraXHUDq9YmPRF4HVkgGr7Lhh8S669tY6qBLPqx6HhRFL1Fjrk9lFYPVvlJdMHVQoVv/9hWrQEufJI0EujKTcEAWmBqzS8syzpkZWdjmqemskA384Aqv8nDA/oV0OykGxYGHEEra8abLFxLXX8/1LSqs5qFB2UY0yYCW1L2gdp1RXe+LliFJ9vrZ5iKNFkSUTu/ZWGp+a4bsLBsaGwuWUhL7XdO5NqB26hqoyWxKEn29UH88qzoiyrpJmRJHGhnbKpE8BvcIg5Z23jaoeex+h9nCwSSRYGLFEXjtAnrE9Fjn04etDb+nHTfKk3bGyN42ltmSBq55BWcVuUS3PUYNdMtGwMGIJexvlaaS1LAKZRGBNymZE7YJILycOkVFWDfJE5ddrRzo3wsYUYKUMy3NRVNReanpRnuQNWM3CwUvLK/RFarbVdN29fwgFZoKqWpkwoo6ySokhQkgTmSJfsDBiiWqzbKZSelGT/HqXDfT+4+qBj2TQ6In/prRJVi81PaUuihAW1xMmVAYMvpRjuQ7Frypu+h6JCkQagVWQPM/uoNa8aVR1GOYJLKSmgqr/s2LEHiyMWKIaOmXSlxBn8BDvUGt3OAqWZyKQmAZZo6QLuQsKvZ3dnATtaFcsP29JcVLXXlVZGmldxbo3jdRmxKz8rOQ7tc1IFQz8jsDCiGO4Eg6+pOmJrMPz/ROR1qv8J6J+fxWije6CWgClQSm9eX11RqYXGKWKyvJkSzo0dBZpKNoinRo9T18EEKUvWnBFsR2/RLHoIqlfrn1LfZkmQW8aZdMtaEBF94tWnhd6r9JAVU0te9NYg4URS1SDhJw3jyDbY5GrX7N9yzTRz8fZa0i7vhgV6u7aK2mB+iyxqEyep6OdKLs4I/KKXRz3HX18kbAwYgl7BqwZxhkRlB1VR1Khyo32ydHPoi4vYvQTaju0lmmI6U7UFPwIS0t4tBOwzEIZ8YvwlyddRhAfVyl3dJf44iIzmzQur1CxN41xKX7kYfXNysvKDkctjNDKqHxXrUVgdVAQigMLI5aorm6hTxK2EpHpCSpbrdgmGirgaANWz/e3HQNWigVrOJ9pfYHijPLHKce0LkARZ4TQEN0IrCbX62KckRKqd8WW3Y5pOPi4mziakDebEfdaRIOFEUtUg5RqtmtvMmlV9LkgBr9G41UQKi8qvTCBPVV+MFV4vwtR2gQGaCuakWRsRmKVp+t6qtKMhGxG8qcsL+9NY6k8+S0wlZJNWxKPvAU9yyssjFjCVp/UMmBNUAamKhWTGh+qQbizhY5rbyL153YV2gyZsa3OMkHSoeNF70csA9YcvG5Z9UO1ay/RgJWQh1JuNcPCiCWofcfUipxaTvCwzg6ZcYQbrXDw2mVLXHt9ywmSFni+f0L5lOVF2Agon0tguUToeUO1GSm79gZCJwnDwVe20Qxfu0z6a4xrVZarY58UsWynSiNdjlG0K/TeRdkbOWjAKvJSC2LNfsioXwX6d0o3R1VNjYUZ1GQ8VB2nluea8o6FEUv0R0kW0FNHx7ObEExwkQc069AtLqZtRNxBQxxnxD42Bi0bxof2l2n06pEFQ+vNo7fElwSxIrCiLwKrLUNR6gdT3PKSRnU/XNy1N6+wMJIyUX1XGD9AFPq5IEsbzkvVePh94YlxRk5g0euRXDZpozxBnXLjxujyyOcDaeOMozJvGmFajWuIqi/4Nz0/7ZgNZMJwEgasWt43EfU4bcCqOmfpQZoUUwzEvElLNlEtucl37ZWv01Bsv1SU0suqoJbnmhzFwggTiwRlECmy3UXjlh/WtESo2kXHEtAUldIFLfdFQmYimhEbZTimEgYgbZRcY6LxbA2akzXl7mVN4NAT6qLLywbVc3fRmyavsDDiGDp2G9X+GvB73kt5KMzx/ciTEayVXXsTlr7EEVjjxRlxnawEWhNvGpGGuvy3rZhUeR4QBLAwwpRJy7VX32Ar+gvLg8xw0iPXGTSOU6qrIb72shGZr21iY1j63jS9/4YeT6QBq9noHboP2nFhaMd0sWEYS1HzU4xfg2WGXHv1muUEfYoRhW2MRnmq+2gmrAXeI4vSiTq2ihzWjNiDhRGGcZzS5JCVkXQeJ9Y49FjQjFTrrr1ZkmS7VGWrnmV/dVxIAhZGHEOnb1sPB18wVyVSvnS0oqGi4sOfYAAq02T0aSo0v+6jXHs9tWtv0IVUmJbalpJmRBG7QJVPl7hGgnFtaaTlKjRR9DKiDXylu/ZKj4f7QtITOsV43bRMtQFrfLsZU4PuoI4zLZnJaJlGtVGepeWVapODWBhhYkMeoGKMHpQq7Lt+RhiwxpwcdeOMBMnT3jQ27C1s31v5NgMyzYhCla+5TONinJGSOGPPtTf+c/SXZ96WyLIV55SuvQ6GYHVUsRUJCyO5xu6L4IsS6IBxFDW6YbVTGlzyvD7tqupfhJVde5PWjEjc/Y3Ly0HfymrpS60ZkW1ZGPR8q/jbmgFrdcHCCFPG9CUJRkaUpgv8Sy4fBC0FopZNNOuMuCZPUmbZYNbzpxUHSNMzYA3t2huVj1S6vL7S37qGsOIAdRrqfQ2FhU5AuN52iP/2lyn5ole0K6wZUV+vi3FGSBFYNcpT3V8TucJDuG/aQmnAqnTttdcGWzjYJBIsjDCM4/QNhXkdZvqfZiRP15sXstp8UBn0LAcapbzAwohjZGrAaugLTzfE1BtMKptQmVW2hGTdZiSivNiDo6bNiMooLlEs3FcrX9SW1z7krqfSBsjLoie1gjjOSIzyYF/UzZNApjTaVZyVLtOk8K5WmxzEwggTG8/Tmya0Y0NQVOARE0vqgkrgR5zqS3l1xx5TYSkYDt7KrUtoZtJfQopOY2fX3hzNxBrYuiyTYoLLYTY1JWrPOfm5ahMIsoSFEaZM0i9WnLGDktW+N43++SRsHKWakRwt2+gJq3o2G6bIipMJEip1fWijvBzKIvaNWO0+x6yi+JoYsDL6sDDiGK6Eg9cpO2hYpkrX+y9tUOmLe+BFLtNEGSOafEGrv7zE6g5RLBV5BFZ6WwCBhX5SHSBowBpTkwVo2ltoHNee2Ahf1rpCimncjDiIHn0c4bRQoL7zFgyRYRaBtVgMau3soRofTFx7ORy8PiyMMGWqq2tXDzJvmjyRJ02B7q69TDpkdftVwohs115GHxZGHEPPgNW6BatRO3S/8OnN8Zmw9h2Xbg+f7nClciU2za9KF3ze6dmvxr+vVmyKUnq+qi96eaZk2iJD+O7HMmAtWNe02X6MSb7fpu7MUllEFYHV0o2uthUiFkYYK9iII0FNL17yUKvctes0iL4qqreUNs6Ebj54G+aT/E3PH09I06tLN310Dt1de/O0I3FcMjVgDdSf1rcH24ykAwsjTBnTNUjdL3yjOiptRggBrWwQ7dqrn8ckbSlZ6LpTGgdtDPpawqrM8DF+M/zlyYQL6XF5C6pBILGuGdG8v9EFGjclMXiVxh4sjDiG1jJNcs3QUiWSI7CeSEMeUyo27orKIzWiLdVpoI2J2kpdKIwgfJHytPS2AAabFxqO3l7g81Nb+6B4Dsb5peXqtc53aZJG6e7aa2LkGxexAWuM8oiZtZbbVEKlwf0KuplbNWA1LEy6ZYUqHLxZVVUPCyMpYxYGma72Dh6WhUkXIXqvqtFoL2/XVHbtDQ1w+RnW0o67Eac6nU39TNHViqWB6/3Jxfe21oI6SX+pUX1c9yPHFVgYYXIBxXgtrQidffXp5/GnpS5v9ZJVBFYbhoNpL/WQyrNoYZn6uC6MwBrDtVdSZhxMlrtUJCkkmvYtF3ftzSssjKRM1Hgh3I1TskMnxaC+cOJ/pLaJjiWgvqUmLlVNEkQ0jAsp1xS5LBQpqPQl0I1QG66rN7eusVx2Bqy0YzaQlRvHrkh30jO5Nhc3yqNgz4DVRODzx+vJaq+aSmTPMWzfJY8zovuMS+ll3nXU8lyzvWVhhClj+mVFd+2NYcBqsR226hTvTmuv/GC6jOxX7Wg1krIZiYFc3W0wUWY/L8Ymrb1pjO1Xk9SMGJbN3jT2YGHEMfQMWKv7ReD3vBdPJo3kiDx5m6RhMxKXrAxYs8TFxyJbpVF9ONgat3PwyLRgYYQpY9q5PdDcCfoMrPQ9ICj2GyobDl2tjOepQ1ZLl14E3juerH5NI8aw5lf9xGzEJzEyuBZdqo5mRMO1V99LqnL5TJZGv8w8CVsyKJpRGy7axOFCkC+5+2xaKmtG7MHCCBObpCKw+vOa240Y12lQn5XBOlTPCW+ajAa+tJcg0lumERdo4vlTDcs0tjGKZKsqL0ZbIss2fIBZvZPViJEwcs899+DUU09FY2MjLr30UqxatUqZ/tFHH8WUKVPQ2NiI8847D0899ZRRY/sDOl3bejT4ivK0NQk6ackGrDqxTiRf0yVNBbkkWnodQaU3Zok55TgjgeNRz994bd5Xt5mhYZCkXHu1tWyENEXNdZos5BDRJBhvPKC9bdYMWA3KKRb9L5ILAmCtZAYNGZcabrWhotrkIG1h5Be/+AXmz5+Pb33rW3j11Vcxbdo0zJ49G3v27BGmf+mll3DdddfhxhtvxNq1azFnzhzMmTMHGzZsiN14xi7mEVip6ewYsMq/RlJWjWjEfxHmJi/TlDQj/uO52ptGa5kmuXb4yrNoYOnAvBib9FzFDfPZbYaVstm11x7awsj3v/993HTTTbjhhhtwzjnn4L777sOgQYPwwAMPCNP/8Ic/xKc//WncdtttOPvss/Gd73wHF154If71X/81duOrkWqTduPA96KX0uCd5/XpPNlUpB2gzQSxAWuMOCM56FouPhZ5BNbg74L0nHHdlspxhTqdxJ2dnVizZg0WLFhQPlZTU4NZs2ZhxYoVwjwrVqzA/Pnzfcdmz56NxYsXS+vp6OhAR0dH+Xd7e7tOMxlTDHv3nU+/ifUftEWmW/3+h7jjNxul4bZl/HDpO+joKirTbNzZjsMd3aHjb7a2447fbETbsS6tOn+yfAv2He6Qnv+Pl95HR3e4TdsOHMUdv9mI7QeOlo998OExPLxyWyjtz1dtw/J390W2Zcu+I8LjURPIE+t2YOPO6OcSZMOOvjxPb2jF+h1679/SN/dg7yH/vVv9/ofCtP/zvzaGrqOrR/ysX3x3H+74zUbfsTVbxeXKuOt3m9A4oBYA8Lqkz768+YBWmfc89y52tR3XyuMiFGHmV2s+wKvbaPd8/+FO4fHfvL4TH3x4TKttAPDMxlbsr3gnf/dGK3a26ZcjolPwLlNgxYg9tISRffv2oaenB83Nzb7jzc3NeOutt4R5WltbhelbW1ul9SxcuBB33HGHTtOsMX3ScN/vGZNO0i6jtqaAnqKHy04bCQA4/eQh5XOTRw1W5h3SMCB07GMfGVX+e1xTI3a2HceVHxmNwQ3hx/eJs3vv9Rmjh+DdPYcx65xmjBpSL61v1tmjy3831PUpyoY19rZj5GBx3hmnnIQ3drbjWFcPHno5PNGKeKv1EN5qPQSg7x5VcunkEVi55QBOGTkIADC0sQ5HO3vwqzUf+NKdPWYoXnh7r++YbMLeuv8oHnzxfd+x0yqeh4zfvr5Lef7pDeL+u+dQR6i+fYc7sOSN3aG0v39TvLQp49LJI8r3DwCGNob7SiV/eGcf/vBOtLCjYuWWA1i5RT45TxoxCNsqBC+gV0CgCgmLXnqf3JYNO9qxQSIY1dfWoLNCiDl5SAMAYPa5zXh2Y9+9//mq7ZH1vLlLT/h6bO0OrfSAf0xQ8ZExQ4XHhzaG3/0hgmNUhjbUCceTIMve3otlgXdPlxff3a+VvqGuBh3dRawK9MNX3v8Qr0iE3LQYPlA8PjYM8C86VD6vxvpa37lZZzeX+1Bp7FMxaeTgE2X63/+JI3rzfvTMUXhjVzsGB+oJQu2DaVHwNCzUdu7cifHjx+Oll15CS0tL+fjtt9+OZcuWYeXKlaE89fX1+I//+A9cd9115WP/9m//hjvuuAO7d4cHaECsGZk4cSLa2towbNgwanO1eG/vYazcfAB/ftEE1NXWYPPew3i54neQrfuPYPm7+1BbKGDq+CZMHd9UPrf9wFEse3svrr1oAhrqejvE4rU7MHnUYEybOBxPrNuB17a34TPTxmK6QNj5zWs7sbv9OP5oymi8+O4+fG7GBAyq7+3MrW3HseSNVnz2wgkY3FCHp9fvwvYPj+KT54zB8nf24s8unIAhDXXYc+g4nt3QijnTx2No4wD8bmMrOrqL2HbgKGprCph97hj84Z29uOaC8Wga2Nepn3trNza1HsZ1l0zE8EH1+PBIJ37+yjacM3YYCoUCDh7tRNuxLnzm/HFYv6MNK7f0DSzdPR66ejzU1RYwoLaAY51FDKgroKu771iJ8ycMR9PAATh4tAsnDRqAD4924aNnjsLjr36A2eeOwehhjXjl/QN4flPfhH20swcXnTICH59yMh5euQ0fHu1E0QO6uovll/9oZw8G1dei6PV+7TRWDApHO3swbcJwzJk+vnxs/QdteHztDgyqr4UHD0c6ejCkoa68rFD6fbijG0Mb63DoeO+/lar8o509GFxfhyOd3RhUMQAUUMDhjm4Mbqj1/Qbgq4NC87BGXHfJJCxeuwNv7jqEz144HueOG4ZfrfkA7+8/gmOdvddaKMD3tykdXUUMqKvxffmV7u3ZY4dhy94juPS0kThl5CA89PJWdPV4mDq+9/jx7h5hmcMaB2D0sAa8u+cwjnUWMbBevUpcSvOR5qHYcfAYjgg0XwAwqL4Of3zeWDy7sRV72jswckg9vnDxRIwc0oD24114Yu0ODB9Uj7daw0JGd9FDseihvq7G16aeItDd09uvStcNAKeOHIy2Y13YcfAYCij4rqG+thZnNg8pa6OOdvbggonDcerIwdiy7wgmjxqMJ9btxHkThuHPpk9QXvuGHW14q/UQPnfheOFSwJu72vHU+l3l/jhu+EB84eKJJO+Od/ccwiOrtmNQfS3aj3fj9NFD8BeXTEJNAXjkle344MOjqCkUcOh4d7nvFwrw9W0qBRRwtLMHHjzUFApoqOvrl8e7iqg/0ceOdvZg/PCB+KMpo/Hk67vw4dFODKqvxUmD6svHOk70q46uIupqa6TGo3Eo9YFjnUXU1fbqiupqC+ju6X1Xu078O7C+BoPq63DdJZOwcWcbXv+gDRNHDMKm1nZcOOmk8kdhifbjXfj5ym2YPGowPnXuGN+5wx3d+OmKrTja2Y2/uuwUjB7WCAB45f0D2HuoA6OHNmB3eweahzXgpff249qLJmBs00Ac6+zBz1ZuxY6DxzB90kn402njTtzXHjy65gN8/KyTMeGkQXht+8Fy/9uy7whOO3kw3tt7OLIP2qK9vR1NTU2R87eWMNLZ2YlBgwbhV7/6FebMmVM+fv311+PgwYN44oknQnkmTZqE+fPn49Zbby0f+9a3voXFixfjtddes3oxDMMwDMO4A3X+1pIt6+vrMWPGDCxdurR8rFgsYunSpT5NSSUtLS2+9ACwZMkSaXqGYRiGYfoX2ouM8+fPx/XXX4+LLroIl1xyCX7wgx/gyJEjuOGGGwAAc+fOxfjx47Fw4UIAwC233IIrrrgCd911F66++mo88sgjWL16Ne6//367V8IwDMMwTC7RFkY+//nPY+/evfjmN7+J1tZWXHDBBXjmmWfKRqrbtm1DTU2fwmXmzJl4+OGH8U//9E/4+te/jjPPPBOLFy/G1KlT7V0FwzAMwzC5RctmJCvYZoRhGIZh8kciNiMMwzAMwzC2YWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhMYWGEYRiGYZhM0Q4HnwWlILHt7eEtwBmGYRiGcZPSvB0V7D0XwsihQ4cAABMnTsy4JQzDMAzD6HLo0CE0NTVJz+dib5pisYidO3di6NChKBQK1sptb2/HxIkTsX37dt7zxhH4mbgFPw+34OfhHvxM1Hieh0OHDmHcuHG+TXSD5EIzUlNTgwkTJiRW/rBhw7gTOQY/E7fg5+EW/Dzcg5+JHJVGpAQbsDIMwzAMkyksjDAMwzAMkyn9WhhpaGjAt771LTQ0NGTdFOYE/Ezcgp+HW/DzcA9+JnbIhQErwzAMwzDVS7/WjDAMwzAMkz0sjDAMwzAMkyksjDAMwzAMkyksjDAMwzAMkyn9Whi55557cOqpp6KxsRGXXnopVq1alXWTqo6FCxfi4osvxtChQzF69GjMmTMHmzZt8qU5fvw45s2bh5EjR2LIkCH43Oc+h927d/vSbNu2DVdffTUGDRqE0aNH47bbbkN3d3eal1KV3HnnnSgUCrj11lvLx/h5pM+OHTvwl3/5lxg5ciQGDhyI8847D6tXry6f9zwP3/zmNzF27FgMHDgQs2bNwjvvvOMr48CBA/jiF7+IYcOGYfjw4bjxxhtx+PDhtC8l9/T09OAb3/gGJk+ejIEDB+L000/Hd77zHd/eKvw8EsDrpzzyyCNefX2998ADD3gbN270brrpJm/48OHe7t27s25aVTF79mzvwQcf9DZs2OCtW7fO++M//mNv0qRJ3uHDh8tpvvrVr3oTJ070li5d6q1evdq77LLLvJkzZ5bPd3d3e1OnTvVmzZrlrV271nvqqae8UaNGeQsWLMjikqqGVatWeaeeeqp3/vnne7fcckv5OD+PdDlw4IB3yimneF/60pe8lStXeps3b/aeffZZ79133y2nufPOO72mpiZv8eLF3muvveb96Z/+qTd58mTv2LFj5TSf/vSnvWnTpnkvv/yy94c//ME744wzvOuuuy6LS8o13/3ud72RI0d6Tz75pLdlyxbv0Ucf9YYMGeL98Ic/LKfh52GffiuMXHLJJd68efPKv3t6erxx48Z5CxcuzLBV1c+ePXs8AN6yZcs8z/O8gwcPegMGDPAeffTRcpo333zTA+CtWLHC8zzPe+qpp7yamhqvtbW1nObee+/1hg0b5nV0dKR7AVXCoUOHvDPPPNNbsmSJd8UVV5SFEX4e6fM//sf/8D760Y9KzxeLRW/MmDHe9773vfKxgwcPeg0NDd7Pf/5zz/M874033vAAeK+88ko5zdNPP+0VCgVvx44dyTW+Crn66qu9L3/5y75jn/3sZ70vfvGLnufx80iKfrlM09nZiTVr1mDWrFnlYzU1NZg1axZWrFiRYcuqn7a2NgDAiBEjAABr1qxBV1eX71lMmTIFkyZNKj+LFStW4LzzzkNzc3M5zezZs9He3o6NGzem2PrqYd68ebj66qt99x3g55EF//Vf/4WLLroI1157LUaPHo3p06fj3//938vnt2zZgtbWVt8zaWpqwqWXXup7JsOHD8dFF11UTjNr1izU1NRg5cqV6V1MFTBz5kwsXboUb7/9NgDgtddew/Lly3HVVVcB4OeRFLnYKM82+/btQ09Pj28wBYDm5ma89dZbGbWq+ikWi7j11ltx+eWXY+rUqQCA1tZW1NfXY/jw4b60zc3NaG1tLacRPavSOUaPRx55BK+++ipeeeWV0Dl+HumzefNm3HvvvZg/fz6+/vWv45VXXsHf/d3fob6+Htdff335norueeUzGT16tO98XV0dRowYwc9Ek3/4h39Ae3s7pkyZgtraWvT09OC73/0uvvjFLwIAP4+E6JfCCJMN8+bNw4YNG7B8+fKsm9Jv2b59O2655RYsWbIEjY2NWTeHQa+QftFFF+F//+//DQCYPn06NmzYgPvuuw/XX399xq3rf/zyl7/Ez372Mzz88MM499xzsW7dOtx6660YN24cP48E6ZfLNKNGjUJtbW3IQ2D37t0YM2ZMRq2qbm6++WY8+eST+L//9/9iwoQJ5eNjxoxBZ2cnDh486Etf+SzGjBkjfFalcwydNWvWYM+ePbjwwgtRV1eHuro6LFu2DP/8z/+Muro6NDc38/NImbFjx+Kcc87xHTv77LOxbds2AH33VDVejRkzBnv27PGd7+7uxoEDB/iZaHLbbbfhH/7hH/CFL3wB5513Hv7qr/4Kf//3f4+FCxcC4OeRFP1SGKmvr8eMGTOwdOnS8rFisYilS5eipaUlw5ZVH57n4eabb8bjjz+O5557DpMnT/adnzFjBgYMGOB7Fps2bcK2bdvKz6KlpQXr16/3vdxLlizBsGHDQoM4o+YTn/gE1q9fj3Xr1pX/u+iii/DFL36x/Dc/j3S5/PLLQ+7ub7/9Nk455RQAwOTJkzFmzBjfM2lvb8fKlSt9z+TgwYNYs2ZNOc1zzz2HYrGISy+9NIWrqB6OHj2Kmhr/1FhbW4tisQiAn0diZG1BmxWPPPKI19DQ4C1atMh74403vL/+67/2hg8f7vMQYOLzN3/zN15TU5P3/PPPe7t27Sr/d/To0XKar371q96kSZO85557zlu9erXX0tLitbS0lM+XXEk/9alPeevWrfOeeeYZ7+STT2ZXUktUetN4Hj+PtFm1apVXV1fnffe73/Xeeecd72c/+5k3aNAg76GHHiqnufPOO73hw4d7TzzxhPf6669711xzjdCVdPr06d7KlSu95cuXe2eeeSa7khpw/fXXe+PHjy+79j722GPeqFGjvNtvv72chp+HffqtMOJ5nvcv//Iv3qRJk7z6+nrvkksu8V5++eWsm1R1ABD+9+CDD5bTHDt2zPvbv/1b76STTvIGDRrk/dmf/Zm3a9cuXznvv/++d9VVV3kDBw70Ro0a5X3ta1/zurq6Ur6a6iQojPDzSJ/f/OY33tSpU72GhgZvypQp3v333+87XywWvW984xtec3Oz19DQ4H3iE5/wNm3a5Euzf/9+77rrrvOGDBniDRs2zLvhhhu8Q4cOpXkZVUF7e7t3yy23eJMmTfIaGxu90047zfvHf/xHn9s6Pw/7FDyvIqwcwzAMwzBMyvRLmxGGYRiGYdyBhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTKFhRGGYRiGYTLl/wc25uQ5yzG7vQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
